{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../../img/ods_stickers.jpg\" />\n",
    "    \n",
    "## [mlcourse.ai](https://mlcourse.ai) – Open Machine Learning Course \n",
    "Author: [Yury Kashnitskiy](https://yorko.github.io) (@yorko). Edited by Sergey Kolchenko (@KolchenkoSergey). This material is subject to the terms and conditions of the [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/) license. Free use is permitted for any non-commercial purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Assignment #6\n",
    "### <center> Beating baselines in \"How good is your Medium article?\"\n",
    "    \n",
    "<img src='../../img/medium_claps.jpg' width=40% />\n",
    "\n",
    "\n",
    "[Competition](https://www.kaggle.com/c/how-good-is-your-medium-article). The task is to beat \"A6 baseline\" (~1.45 Public LB score). Do not forget about our shared [\"primitive\" baseline](https://www.kaggle.com/kashnitsky/ridge-countvectorizer-baseline) - you'll find something valuable there.\n",
    "\n",
    "**Your task:**\n",
    " 1. \"Freeride\". Come up with good features to beat the baseline \"A6 baseline\" (for now, public LB is only considered)\n",
    " 2. You need to name your [team](https://www.kaggle.com/c/how-good-is-your-medium-article/team) (out of 1 person) in full accordance with the [course rating](https://drive.google.com/open?id=19AGEhUQUol6_kNLKSzBsjcGUU3qWy3BNUg8x8IFkO3Q). You can think of it as a part of the assignment. 16 credits for beating the mentioned baseline and correct team naming.\n",
    " \n",
    "*For discussions, please stick to [ODS Slack](https://opendatascience.slack.com/), channel #mlcourse_ai, pinned thread __#a6__*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\alexander.brukhanov\\AppData\\Roaming\\nltk_data\n",
      "[nltk_data]     ...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm_notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.linear_model import Ridge\n",
    "from matplotlib import pyplot as plt\n",
    "import re\n",
    "import nltk.data\n",
    "nltk.download('punkt')\n",
    "tokenizer = nltk.data.load('nltk:tokenizers/punkt/english.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will help to throw away all HTML tags from an article content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from html.parser import HTMLParser\n",
    "\n",
    "class MLStripper(HTMLParser):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        self.strict = False\n",
    "        self.convert_charrefs= True\n",
    "        self.fed = []\n",
    "    def handle_data(self, d):\n",
    "        self.fed.append(d)\n",
    "    def get_data(self):\n",
    "        return ''.join(self.fed)\n",
    "\n",
    "def strip_tags(html):\n",
    "    s = MLStripper()\n",
    "    s.feed(html)\n",
    "    return s.get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supplementary function to read a JSON line without crashing on escape characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_line(line=None):\n",
    "    result = None\n",
    "    try:        \n",
    "        result = json.loads(line)\n",
    "    except Exception as e:      \n",
    "        # Find the offending character index:\n",
    "        idx_to_replace = int(str(e).split(' ')[-1].replace(')',''))      \n",
    "        # Remove the offending character:\n",
    "        new_line = list(line)\n",
    "        new_line[idx_to_replace] = ' '\n",
    "        new_line = ''.join(new_line)     \n",
    "        return read_json_line(line=new_line)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract features `content`, `published`, `title` and `author`, write them to separate files for train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_and_write(path_to_data,\n",
    "                               inp_filename, is_train=True):\n",
    "    \n",
    "    features = ['image']\n",
    "    prefix = 'train' if is_train else 'test'\n",
    "    feature_files = [open(os.path.join(path_to_data,\n",
    "                                       '{}_{}.txt'.format(prefix, feat)),\n",
    "                          'w', encoding='utf-8')\n",
    "                     for feat in features]\n",
    "    \n",
    "    with open(os.path.join(path_to_data, inp_filename), \n",
    "              encoding='utf-8') as inp_json_file:\n",
    "        \n",
    "        for line in tqdm_notebook(inp_json_file):\n",
    "            json_data = read_json_line(line)\n",
    "            #content = json_data['content'].replace('\\n', ' ').replace('\\r', ' ')\n",
    "            #content_no_html_tags = strip_tags(content)\n",
    "            #feature_files[0].write(content_no_html_tags + \"\\n\")\n",
    "            #published = json_data['published']['$date']\n",
    "            #feature_files[1].write(published +\"\\n\")\n",
    "            image_ = json_data['image_url']\n",
    "            feature_files[0].write(str(image_)+\"\\n\")\n",
    "            # You code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATA = 'kaggle_medium' # modify this if you need to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e70ead7b1984d3c83a324a4f4bfdb28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "extract_features_and_write(PATH_TO_DATA, 'train.json', is_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e89059ba2131461ba6004b6311d9446f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "extract_features_and_write(PATH_TO_DATA, 'test.json', is_train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add the following groups of features:**\n",
    "    - Tf-Idf with article content (ngram_range=(1, 2), max_features=100000 but you can try adding more)\n",
    "    - Tf-Idf with article titles (ngram_range=(1, 2), max_features=100000 but you can try adding more)\n",
    "    - Time features: publication hour, whether it's morning, day, night, whether it's a weekend\n",
    "    - Bag of authors (i.e. One-Hot-Encoded author names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_content_sparse = pd.read_csv(PATH_TO_DATA+'/train_content.txt', sep=\"\\n\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_content_sparse=X_train_content_sparse.rename(columns={0: \"content\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MediumEveryone’s stories and ideasAug 13, 2012...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MediumEveryone’s stories and ideasAug 2, 2015 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yun-Chen Chien（簡韻真）Nobody in @g0v.tw, PM in se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vaibhav KhulbeAndroid App Developer | I write ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vaibhav KhulbeAndroid App Developer | I write ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content\n",
       "0  MediumEveryone’s stories and ideasAug 13, 2012...\n",
       "1  MediumEveryone’s stories and ideasAug 2, 2015 ...\n",
       "2  Yun-Chen Chien（簡韻真）Nobody in @g0v.tw, PM in se...\n",
       "3  Vaibhav KhulbeAndroid App Developer | I write ...\n",
       "4  Vaibhav KhulbeAndroid App Developer | I write ..."
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_content_sparse.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_content_sparse = pd.read_csv(PATH_TO_DATA+'/test_content.txt', sep=\"\\n\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_content_sparse=X_test_content_sparse.rename(columns={0: \"content\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_wordlist(sentence, remove_stopwords=False):\n",
    "    # 1. Remove non-letters\n",
    "    sentence_text = re.sub(r'[^\\w\\s]','', sentence)\n",
    "    # 2. Convert words to lower case and split them\n",
    "    words = sentence_text.lower().split()\n",
    "    # 3. Return a list of words\n",
    "    return(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oped_to_sentences(oped, tokenizer, remove_stopwords=False ):\n",
    "    try:\n",
    "        # 1. Use the NLTK tokenizer to split the text into sentences\n",
    "        raw_sentences = tokenizer.tokenize(oped.strip())\n",
    "        # 2. Loop over each sentence\n",
    "        sentences = []\n",
    "        for raw_sentence in raw_sentences:\n",
    "            # If a sentence is empty, skip it\n",
    "            if len(raw_sentence) > 0:\n",
    "                # Otherwise, call sentence_to_wordlist to get a list of words\n",
    "                sentences.append(sentence_to_wordlist(raw_sentence))\n",
    "        # 3. Return the list of sentences (each sentence is a list of words, so this returns a list of lists)\n",
    "        len(sentences)\n",
    "        return sentences\n",
    "    except:\n",
    "        print('nope')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#content_list = pd.concat([X_train_content_sparse,X_test_content_sparse],axis = 0,ignore_index = True)['content'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_list = pd.concat(X_train_content_sparse, X_test_content_sparse)['content'].tolist()\n",
    "sentences = []\n",
    "\n",
    "for i in range(0,len(content_list)):\n",
    "    try:\n",
    "        # Need to first change \"./.\" to \".\" so that sentences parse correctly\n",
    "        oped = content_list[i].replace(\"/.\", '')\n",
    "        # Now apply functions\n",
    "        sentences += oped_to_sentences(oped, tokenizer)\n",
    "    except:\n",
    "        print('no!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexander.brukhanov\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1209: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import word2vec\n",
    "from gensim.models import Phrases\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',\\\n",
    "    level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 300    # Word vector dimensionality                      \n",
    "min_word_count = 50   # Minimum word count                        \n",
    "num_workers = 4       # Number of threads to run in parallel\n",
    "context = 6           # Context window size                                                                                    \n",
    "downsampling = 1e-3   # Downsample setting for frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-18 19:37:12,013 : INFO : collecting all words and their counts\n",
      "2018-11-18 19:37:12,017 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-11-18 19:37:12,153 : INFO : PROGRESS: at sentence #10000, processed 277461 words, keeping 36705 word types\n",
      "2018-11-18 19:37:12,201 : INFO : PROGRESS: at sentence #20000, processed 537635 words, keeping 61356 word types\n",
      "2018-11-18 19:37:12,264 : INFO : PROGRESS: at sentence #30000, processed 808600 words, keeping 86367 word types\n",
      "2018-11-18 19:37:12,468 : INFO : PROGRESS: at sentence #40000, processed 1072610 words, keeping 108188 word types\n",
      "2018-11-18 19:37:12,545 : INFO : PROGRESS: at sentence #50000, processed 1364528 words, keeping 125926 word types\n",
      "2018-11-18 19:37:12,596 : INFO : PROGRESS: at sentence #60000, processed 1639124 words, keeping 146161 word types\n",
      "2018-11-18 19:37:12,634 : INFO : PROGRESS: at sentence #70000, processed 1828091 words, keeping 154665 word types\n",
      "2018-11-18 19:37:12,691 : INFO : PROGRESS: at sentence #80000, processed 2087832 words, keeping 173699 word types\n",
      "2018-11-18 19:37:12,775 : INFO : PROGRESS: at sentence #90000, processed 2371353 words, keeping 198072 word types\n",
      "2018-11-18 19:37:12,846 : INFO : PROGRESS: at sentence #100000, processed 2655025 words, keeping 215900 word types\n",
      "2018-11-18 19:37:12,912 : INFO : PROGRESS: at sentence #110000, processed 2960458 words, keeping 230251 word types\n",
      "2018-11-18 19:37:12,960 : INFO : PROGRESS: at sentence #120000, processed 3211272 words, keeping 245438 word types\n",
      "2018-11-18 19:37:13,019 : INFO : PROGRESS: at sentence #130000, processed 3454302 words, keeping 255871 word types\n",
      "2018-11-18 19:37:13,066 : INFO : PROGRESS: at sentence #140000, processed 3723043 words, keeping 270563 word types\n",
      "2018-11-18 19:37:13,120 : INFO : PROGRESS: at sentence #150000, processed 3992339 words, keeping 287454 word types\n",
      "2018-11-18 19:37:13,183 : INFO : PROGRESS: at sentence #160000, processed 4265501 words, keeping 306382 word types\n",
      "2018-11-18 19:37:13,245 : INFO : PROGRESS: at sentence #170000, processed 4550458 words, keeping 318620 word types\n",
      "2018-11-18 19:37:13,311 : INFO : PROGRESS: at sentence #180000, processed 4802358 words, keeping 327839 word types\n",
      "2018-11-18 19:37:13,370 : INFO : PROGRESS: at sentence #190000, processed 5079338 words, keeping 340742 word types\n",
      "2018-11-18 19:37:13,449 : INFO : PROGRESS: at sentence #200000, processed 5347600 words, keeping 351687 word types\n",
      "2018-11-18 19:37:13,503 : INFO : PROGRESS: at sentence #210000, processed 5626701 words, keeping 365505 word types\n",
      "2018-11-18 19:37:13,554 : INFO : PROGRESS: at sentence #220000, processed 5905868 words, keeping 377899 word types\n",
      "2018-11-18 19:37:13,611 : INFO : PROGRESS: at sentence #230000, processed 6184007 words, keeping 389850 word types\n",
      "2018-11-18 19:37:13,659 : INFO : PROGRESS: at sentence #240000, processed 6441956 words, keeping 402755 word types\n",
      "2018-11-18 19:37:13,716 : INFO : PROGRESS: at sentence #250000, processed 6733927 words, keeping 420119 word types\n",
      "2018-11-18 19:37:13,775 : INFO : PROGRESS: at sentence #260000, processed 7008674 words, keeping 434050 word types\n",
      "2018-11-18 19:37:13,837 : INFO : PROGRESS: at sentence #270000, processed 7295071 words, keeping 448322 word types\n",
      "2018-11-18 19:37:13,890 : INFO : PROGRESS: at sentence #280000, processed 7575980 words, keeping 458919 word types\n",
      "2018-11-18 19:37:13,942 : INFO : PROGRESS: at sentence #290000, processed 7848013 words, keeping 470183 word types\n",
      "2018-11-18 19:37:13,987 : INFO : PROGRESS: at sentence #300000, processed 8085530 words, keeping 481130 word types\n",
      "2018-11-18 19:37:14,037 : INFO : PROGRESS: at sentence #310000, processed 8332739 words, keeping 488979 word types\n",
      "2018-11-18 19:37:14,092 : INFO : PROGRESS: at sentence #320000, processed 8623273 words, keeping 501458 word types\n",
      "2018-11-18 19:37:14,142 : INFO : PROGRESS: at sentence #330000, processed 8868055 words, keeping 510717 word types\n",
      "2018-11-18 19:37:14,193 : INFO : PROGRESS: at sentence #340000, processed 9131648 words, keeping 520321 word types\n",
      "2018-11-18 19:37:14,249 : INFO : PROGRESS: at sentence #350000, processed 9393049 words, keeping 532754 word types\n",
      "2018-11-18 19:37:14,309 : INFO : PROGRESS: at sentence #360000, processed 9663531 words, keeping 542484 word types\n",
      "2018-11-18 19:37:14,356 : INFO : PROGRESS: at sentence #370000, processed 9868092 words, keeping 551607 word types\n",
      "2018-11-18 19:37:14,418 : INFO : PROGRESS: at sentence #380000, processed 10128912 words, keeping 569221 word types\n",
      "2018-11-18 19:37:14,481 : INFO : PROGRESS: at sentence #390000, processed 10390967 words, keeping 581321 word types\n",
      "2018-11-18 19:37:14,543 : INFO : PROGRESS: at sentence #400000, processed 10664025 words, keeping 592720 word types\n",
      "2018-11-18 19:37:14,598 : INFO : PROGRESS: at sentence #410000, processed 10909533 words, keeping 603155 word types\n",
      "2018-11-18 19:37:14,654 : INFO : PROGRESS: at sentence #420000, processed 11183365 words, keeping 612276 word types\n",
      "2018-11-18 19:37:14,714 : INFO : PROGRESS: at sentence #430000, processed 11455143 words, keeping 623502 word types\n",
      "2018-11-18 19:37:14,782 : INFO : PROGRESS: at sentence #440000, processed 11754506 words, keeping 635640 word types\n",
      "2018-11-18 19:37:14,846 : INFO : PROGRESS: at sentence #450000, processed 12017327 words, keeping 649997 word types\n",
      "2018-11-18 19:37:14,906 : INFO : PROGRESS: at sentence #460000, processed 12278991 words, keeping 666983 word types\n",
      "2018-11-18 19:37:14,967 : INFO : PROGRESS: at sentence #470000, processed 12553411 words, keeping 675790 word types\n",
      "2018-11-18 19:37:15,025 : INFO : PROGRESS: at sentence #480000, processed 12824067 words, keeping 687220 word types\n",
      "2018-11-18 19:37:15,083 : INFO : PROGRESS: at sentence #490000, processed 13096563 words, keeping 694537 word types\n",
      "2018-11-18 19:37:15,186 : INFO : PROGRESS: at sentence #500000, processed 13374554 words, keeping 706123 word types\n",
      "2018-11-18 19:37:15,242 : INFO : PROGRESS: at sentence #510000, processed 13646023 words, keeping 716285 word types\n",
      "2018-11-18 19:37:15,303 : INFO : PROGRESS: at sentence #520000, processed 13920465 words, keeping 726251 word types\n",
      "2018-11-18 19:37:15,362 : INFO : PROGRESS: at sentence #530000, processed 14197271 words, keeping 736413 word types\n",
      "2018-11-18 19:37:15,417 : INFO : PROGRESS: at sentence #540000, processed 14470585 words, keeping 745447 word types\n",
      "2018-11-18 19:37:15,477 : INFO : PROGRESS: at sentence #550000, processed 14754600 words, keeping 754995 word types\n",
      "2018-11-18 19:37:15,541 : INFO : PROGRESS: at sentence #560000, processed 15045514 words, keeping 770971 word types\n",
      "2018-11-18 19:37:15,595 : INFO : PROGRESS: at sentence #570000, processed 15293907 words, keeping 780474 word types\n",
      "2018-11-18 19:37:15,654 : INFO : PROGRESS: at sentence #580000, processed 15569673 words, keeping 790871 word types\n",
      "2018-11-18 19:37:15,712 : INFO : PROGRESS: at sentence #590000, processed 15846617 words, keeping 800020 word types\n",
      "2018-11-18 19:37:15,777 : INFO : PROGRESS: at sentence #600000, processed 16150095 words, keeping 811148 word types\n",
      "2018-11-18 19:37:15,845 : INFO : PROGRESS: at sentence #610000, processed 16450722 words, keeping 821154 word types\n",
      "2018-11-18 19:37:15,912 : INFO : PROGRESS: at sentence #620000, processed 16737722 words, keeping 830444 word types\n",
      "2018-11-18 19:37:15,970 : INFO : PROGRESS: at sentence #630000, processed 17003302 words, keeping 838188 word types\n",
      "2018-11-18 19:37:16,025 : INFO : PROGRESS: at sentence #640000, processed 17245747 words, keeping 852057 word types\n",
      "2018-11-18 19:37:16,091 : INFO : PROGRESS: at sentence #650000, processed 17524899 words, keeping 863729 word types\n",
      "2018-11-18 19:37:16,152 : INFO : PROGRESS: at sentence #660000, processed 17803156 words, keeping 871603 word types\n",
      "2018-11-18 19:37:16,209 : INFO : PROGRESS: at sentence #670000, processed 18070960 words, keeping 880081 word types\n",
      "2018-11-18 19:37:16,277 : INFO : PROGRESS: at sentence #680000, processed 18406912 words, keeping 891751 word types\n",
      "2018-11-18 19:37:16,334 : INFO : PROGRESS: at sentence #690000, processed 18683422 words, keeping 902487 word types\n",
      "2018-11-18 19:37:16,389 : INFO : PROGRESS: at sentence #700000, processed 18933470 words, keeping 913136 word types\n",
      "2018-11-18 19:37:16,445 : INFO : PROGRESS: at sentence #710000, processed 19191338 words, keeping 922026 word types\n",
      "2018-11-18 19:37:16,499 : INFO : PROGRESS: at sentence #720000, processed 19449997 words, keeping 930250 word types\n",
      "2018-11-18 19:37:16,553 : INFO : PROGRESS: at sentence #730000, processed 19711462 words, keeping 939323 word types\n",
      "2018-11-18 19:37:16,610 : INFO : PROGRESS: at sentence #740000, processed 19997712 words, keeping 947848 word types\n",
      "2018-11-18 19:37:16,672 : INFO : PROGRESS: at sentence #750000, processed 20272297 words, keeping 960049 word types\n",
      "2018-11-18 19:37:16,729 : INFO : PROGRESS: at sentence #760000, processed 20553117 words, keeping 973031 word types\n",
      "2018-11-18 19:37:16,786 : INFO : PROGRESS: at sentence #770000, processed 20834971 words, keeping 982234 word types\n",
      "2018-11-18 19:37:16,843 : INFO : PROGRESS: at sentence #780000, processed 21109213 words, keeping 993764 word types\n",
      "2018-11-18 19:37:16,887 : INFO : PROGRESS: at sentence #790000, processed 21356434 words, keeping 1004469 word types\n",
      "2018-11-18 19:37:16,938 : INFO : PROGRESS: at sentence #800000, processed 21630387 words, keeping 1016507 word types\n",
      "2018-11-18 19:37:16,990 : INFO : PROGRESS: at sentence #810000, processed 21915185 words, keeping 1026590 word types\n",
      "2018-11-18 19:37:17,041 : INFO : PROGRESS: at sentence #820000, processed 22170318 words, keeping 1039175 word types\n",
      "2018-11-18 19:37:17,090 : INFO : PROGRESS: at sentence #830000, processed 22451267 words, keeping 1048763 word types\n",
      "2018-11-18 19:37:17,142 : INFO : PROGRESS: at sentence #840000, processed 22734493 words, keeping 1058067 word types\n",
      "2018-11-18 19:37:17,195 : INFO : PROGRESS: at sentence #850000, processed 23006163 words, keeping 1066809 word types\n",
      "2018-11-18 19:37:17,246 : INFO : PROGRESS: at sentence #860000, processed 23273868 words, keeping 1078520 word types\n",
      "2018-11-18 19:37:17,294 : INFO : PROGRESS: at sentence #870000, processed 23541372 words, keeping 1086148 word types\n",
      "2018-11-18 19:37:17,341 : INFO : PROGRESS: at sentence #880000, processed 23805481 words, keeping 1094280 word types\n",
      "2018-11-18 19:37:17,387 : INFO : PROGRESS: at sentence #890000, processed 24065260 words, keeping 1101575 word types\n",
      "2018-11-18 19:37:17,439 : INFO : PROGRESS: at sentence #900000, processed 24336750 words, keeping 1112090 word types\n",
      "2018-11-18 19:37:17,488 : INFO : PROGRESS: at sentence #910000, processed 24595896 words, keeping 1124428 word types\n",
      "2018-11-18 19:37:17,537 : INFO : PROGRESS: at sentence #920000, processed 24879673 words, keeping 1133576 word types\n",
      "2018-11-18 19:37:17,587 : INFO : PROGRESS: at sentence #930000, processed 25165412 words, keeping 1143079 word types\n",
      "2018-11-18 19:37:17,636 : INFO : PROGRESS: at sentence #940000, processed 25443712 words, keeping 1152668 word types\n",
      "2018-11-18 19:37:17,685 : INFO : PROGRESS: at sentence #950000, processed 25708738 words, keeping 1162666 word types\n",
      "2018-11-18 19:37:17,732 : INFO : PROGRESS: at sentence #960000, processed 25982530 words, keeping 1169953 word types\n",
      "2018-11-18 19:37:17,780 : INFO : PROGRESS: at sentence #970000, processed 26272969 words, keeping 1175864 word types\n",
      "2018-11-18 19:37:17,832 : INFO : PROGRESS: at sentence #980000, processed 26567621 words, keeping 1186771 word types\n",
      "2018-11-18 19:37:17,877 : INFO : PROGRESS: at sentence #990000, processed 26815391 words, keeping 1197425 word types\n",
      "2018-11-18 19:37:17,924 : INFO : PROGRESS: at sentence #1000000, processed 27083309 words, keeping 1204782 word types\n",
      "2018-11-18 19:37:17,972 : INFO : PROGRESS: at sentence #1010000, processed 27346467 words, keeping 1213739 word types\n",
      "2018-11-18 19:37:18,029 : INFO : PROGRESS: at sentence #1020000, processed 27655271 words, keeping 1229225 word types\n",
      "2018-11-18 19:37:18,090 : INFO : PROGRESS: at sentence #1030000, processed 27957412 words, keeping 1241194 word types\n",
      "2018-11-18 19:37:18,142 : INFO : PROGRESS: at sentence #1040000, processed 28208252 words, keeping 1250329 word types\n",
      "2018-11-18 19:37:18,189 : INFO : PROGRESS: at sentence #1050000, processed 28457088 words, keeping 1262692 word types\n",
      "2018-11-18 19:37:18,238 : INFO : PROGRESS: at sentence #1060000, processed 28731272 words, keeping 1270742 word types\n",
      "2018-11-18 19:37:18,287 : INFO : PROGRESS: at sentence #1070000, processed 29014155 words, keeping 1279760 word types\n",
      "2018-11-18 19:37:18,337 : INFO : PROGRESS: at sentence #1080000, processed 29298442 words, keeping 1290032 word types\n",
      "2018-11-18 19:37:18,382 : INFO : PROGRESS: at sentence #1090000, processed 29556665 words, keeping 1297492 word types\n",
      "2018-11-18 19:37:18,430 : INFO : PROGRESS: at sentence #1100000, processed 29828272 words, keeping 1306216 word types\n",
      "2018-11-18 19:37:18,477 : INFO : PROGRESS: at sentence #1110000, processed 30106725 words, keeping 1313604 word types\n",
      "2018-11-18 19:37:18,525 : INFO : PROGRESS: at sentence #1120000, processed 30380164 words, keeping 1322577 word types\n",
      "2018-11-18 19:37:18,574 : INFO : PROGRESS: at sentence #1130000, processed 30653249 words, keeping 1331145 word types\n",
      "2018-11-18 19:37:18,623 : INFO : PROGRESS: at sentence #1140000, processed 30924193 words, keeping 1341572 word types\n",
      "2018-11-18 19:37:18,674 : INFO : PROGRESS: at sentence #1150000, processed 31209370 words, keeping 1351313 word types\n",
      "2018-11-18 19:37:18,724 : INFO : PROGRESS: at sentence #1160000, processed 31492754 words, keeping 1360955 word types\n",
      "2018-11-18 19:37:18,773 : INFO : PROGRESS: at sentence #1170000, processed 31757294 words, keeping 1369286 word types\n",
      "2018-11-18 19:37:18,827 : INFO : PROGRESS: at sentence #1180000, processed 32058546 words, keeping 1377962 word types\n",
      "2018-11-18 19:37:18,877 : INFO : PROGRESS: at sentence #1190000, processed 32317871 words, keeping 1387419 word types\n",
      "2018-11-18 19:37:19,004 : INFO : PROGRESS: at sentence #1200000, processed 32602713 words, keeping 1399465 word types\n",
      "2018-11-18 19:37:19,061 : INFO : PROGRESS: at sentence #1210000, processed 32882140 words, keeping 1407872 word types\n",
      "2018-11-18 19:37:19,113 : INFO : PROGRESS: at sentence #1220000, processed 33179627 words, keeping 1418132 word types\n",
      "2018-11-18 19:37:19,165 : INFO : PROGRESS: at sentence #1230000, processed 33448890 words, keeping 1427862 word types\n",
      "2018-11-18 19:37:19,212 : INFO : PROGRESS: at sentence #1240000, processed 33714667 words, keeping 1435354 word types\n",
      "2018-11-18 19:37:19,265 : INFO : PROGRESS: at sentence #1250000, processed 34003265 words, keeping 1444439 word types\n",
      "2018-11-18 19:37:19,315 : INFO : PROGRESS: at sentence #1260000, processed 34271360 words, keeping 1452860 word types\n",
      "2018-11-18 19:37:19,362 : INFO : PROGRESS: at sentence #1270000, processed 34541371 words, keeping 1460987 word types\n",
      "2018-11-18 19:37:19,409 : INFO : PROGRESS: at sentence #1280000, processed 34794475 words, keeping 1470734 word types\n",
      "2018-11-18 19:37:19,454 : INFO : PROGRESS: at sentence #1290000, processed 35042617 words, keeping 1478453 word types\n",
      "2018-11-18 19:37:19,502 : INFO : PROGRESS: at sentence #1300000, processed 35317037 words, keeping 1486052 word types\n",
      "2018-11-18 19:37:19,549 : INFO : PROGRESS: at sentence #1310000, processed 35563847 words, keeping 1496461 word types\n",
      "2018-11-18 19:37:19,595 : INFO : PROGRESS: at sentence #1320000, processed 35808177 words, keeping 1506930 word types\n",
      "2018-11-18 19:37:19,639 : INFO : PROGRESS: at sentence #1330000, processed 36062017 words, keeping 1514544 word types\n",
      "2018-11-18 19:37:19,691 : INFO : PROGRESS: at sentence #1340000, processed 36343588 words, keeping 1524950 word types\n",
      "2018-11-18 19:37:19,744 : INFO : PROGRESS: at sentence #1350000, processed 36629617 words, keeping 1534017 word types\n",
      "2018-11-18 19:37:19,793 : INFO : PROGRESS: at sentence #1360000, processed 36895782 words, keeping 1540829 word types\n",
      "2018-11-18 19:37:19,838 : INFO : PROGRESS: at sentence #1370000, processed 37144919 words, keeping 1550640 word types\n",
      "2018-11-18 19:37:19,880 : INFO : PROGRESS: at sentence #1380000, processed 37390224 words, keeping 1557218 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-18 19:37:19,921 : INFO : PROGRESS: at sentence #1390000, processed 37621205 words, keeping 1564734 word types\n",
      "2018-11-18 19:37:19,967 : INFO : PROGRESS: at sentence #1400000, processed 37890531 words, keeping 1572240 word types\n",
      "2018-11-18 19:37:20,014 : INFO : PROGRESS: at sentence #1410000, processed 38152964 words, keeping 1580350 word types\n",
      "2018-11-18 19:37:20,063 : INFO : PROGRESS: at sentence #1420000, processed 38408116 words, keeping 1588779 word types\n",
      "2018-11-18 19:37:20,111 : INFO : PROGRESS: at sentence #1430000, processed 38673450 words, keeping 1595684 word types\n",
      "2018-11-18 19:37:20,161 : INFO : PROGRESS: at sentence #1440000, processed 38936463 words, keeping 1605033 word types\n",
      "2018-11-18 19:37:20,210 : INFO : PROGRESS: at sentence #1450000, processed 39203686 words, keeping 1612408 word types\n",
      "2018-11-18 19:37:20,260 : INFO : PROGRESS: at sentence #1460000, processed 39462557 words, keeping 1625712 word types\n",
      "2018-11-18 19:37:20,309 : INFO : PROGRESS: at sentence #1470000, processed 39743987 words, keeping 1633622 word types\n",
      "2018-11-18 19:37:20,364 : INFO : PROGRESS: at sentence #1480000, processed 40036489 words, keeping 1642890 word types\n",
      "2018-11-18 19:37:20,410 : INFO : PROGRESS: at sentence #1490000, processed 40299211 words, keeping 1649954 word types\n",
      "2018-11-18 19:37:20,460 : INFO : PROGRESS: at sentence #1500000, processed 40579819 words, keeping 1658468 word types\n",
      "2018-11-18 19:37:20,509 : INFO : PROGRESS: at sentence #1510000, processed 40835980 words, keeping 1667112 word types\n",
      "2018-11-18 19:37:20,562 : INFO : PROGRESS: at sentence #1520000, processed 41143091 words, keeping 1676537 word types\n",
      "2018-11-18 19:37:20,607 : INFO : PROGRESS: at sentence #1530000, processed 41398848 words, keeping 1684000 word types\n",
      "2018-11-18 19:37:20,654 : INFO : PROGRESS: at sentence #1540000, processed 41656978 words, keeping 1690970 word types\n",
      "2018-11-18 19:37:20,701 : INFO : PROGRESS: at sentence #1550000, processed 41924037 words, keeping 1698862 word types\n",
      "2018-11-18 19:37:20,748 : INFO : PROGRESS: at sentence #1560000, processed 42179340 words, keeping 1709286 word types\n",
      "2018-11-18 19:37:20,798 : INFO : PROGRESS: at sentence #1570000, processed 42454479 words, keeping 1719092 word types\n",
      "2018-11-18 19:37:20,846 : INFO : PROGRESS: at sentence #1580000, processed 42740650 words, keeping 1728927 word types\n",
      "2018-11-18 19:37:20,899 : INFO : PROGRESS: at sentence #1590000, processed 43018532 words, keeping 1739132 word types\n",
      "2018-11-18 19:37:20,944 : INFO : PROGRESS: at sentence #1600000, processed 43281817 words, keeping 1746536 word types\n",
      "2018-11-18 19:37:20,992 : INFO : PROGRESS: at sentence #1610000, processed 43551264 words, keeping 1754657 word types\n",
      "2018-11-18 19:37:21,046 : INFO : PROGRESS: at sentence #1620000, processed 43837519 words, keeping 1763636 word types\n",
      "2018-11-18 19:37:21,097 : INFO : PROGRESS: at sentence #1630000, processed 44112301 words, keeping 1772144 word types\n",
      "2018-11-18 19:37:21,147 : INFO : PROGRESS: at sentence #1640000, processed 44378090 words, keeping 1778401 word types\n",
      "2018-11-18 19:37:21,195 : INFO : PROGRESS: at sentence #1650000, processed 44653311 words, keeping 1786909 word types\n",
      "2018-11-18 19:37:21,239 : INFO : PROGRESS: at sentence #1660000, processed 44904226 words, keeping 1794120 word types\n",
      "2018-11-18 19:37:21,283 : INFO : PROGRESS: at sentence #1670000, processed 45149505 words, keeping 1799774 word types\n",
      "2018-11-18 19:37:21,330 : INFO : PROGRESS: at sentence #1680000, processed 45409758 words, keeping 1808178 word types\n",
      "2018-11-18 19:37:21,377 : INFO : PROGRESS: at sentence #1690000, processed 45667028 words, keeping 1817722 word types\n",
      "2018-11-18 19:37:21,429 : INFO : PROGRESS: at sentence #1700000, processed 45936960 words, keeping 1830152 word types\n",
      "2018-11-18 19:37:21,478 : INFO : PROGRESS: at sentence #1710000, processed 46216888 words, keeping 1839135 word types\n",
      "2018-11-18 19:37:21,525 : INFO : PROGRESS: at sentence #1720000, processed 46488964 words, keeping 1847485 word types\n",
      "2018-11-18 19:37:21,574 : INFO : PROGRESS: at sentence #1730000, processed 46768959 words, keeping 1857541 word types\n",
      "2018-11-18 19:37:21,623 : INFO : PROGRESS: at sentence #1740000, processed 47046313 words, keeping 1865097 word types\n",
      "2018-11-18 19:37:21,672 : INFO : PROGRESS: at sentence #1750000, processed 47312626 words, keeping 1872760 word types\n",
      "2018-11-18 19:37:21,721 : INFO : PROGRESS: at sentence #1760000, processed 47576437 words, keeping 1880622 word types\n",
      "2018-11-18 19:37:21,761 : INFO : PROGRESS: at sentence #1770000, processed 47814713 words, keeping 1884715 word types\n",
      "2018-11-18 19:37:21,797 : INFO : PROGRESS: at sentence #1780000, processed 48031832 words, keeping 1886839 word types\n",
      "2018-11-18 19:37:21,844 : INFO : PROGRESS: at sentence #1790000, processed 48298307 words, keeping 1894564 word types\n",
      "2018-11-18 19:37:21,875 : INFO : PROGRESS: at sentence #1800000, processed 48446593 words, keeping 1903790 word types\n",
      "2018-11-18 19:37:21,923 : INFO : PROGRESS: at sentence #1810000, processed 48713376 words, keeping 1911452 word types\n",
      "2018-11-18 19:37:21,970 : INFO : PROGRESS: at sentence #1820000, processed 48978993 words, keeping 1919990 word types\n",
      "2018-11-18 19:37:22,025 : INFO : PROGRESS: at sentence #1830000, processed 49275742 words, keeping 1932664 word types\n",
      "2018-11-18 19:37:22,075 : INFO : PROGRESS: at sentence #1840000, processed 49543524 words, keeping 1943436 word types\n",
      "2018-11-18 19:37:22,121 : INFO : PROGRESS: at sentence #1850000, processed 49778103 words, keeping 1952347 word types\n",
      "2018-11-18 19:37:22,173 : INFO : PROGRESS: at sentence #1860000, processed 50043696 words, keeping 1962522 word types\n",
      "2018-11-18 19:37:22,222 : INFO : PROGRESS: at sentence #1870000, processed 50317417 words, keeping 1969001 word types\n",
      "2018-11-18 19:37:22,271 : INFO : PROGRESS: at sentence #1880000, processed 50582562 words, keeping 1976551 word types\n",
      "2018-11-18 19:37:22,321 : INFO : PROGRESS: at sentence #1890000, processed 50860497 words, keeping 1984635 word types\n",
      "2018-11-18 19:37:22,373 : INFO : PROGRESS: at sentence #1900000, processed 51141833 words, keeping 1992990 word types\n",
      "2018-11-18 19:37:22,424 : INFO : PROGRESS: at sentence #1910000, processed 51423376 words, keeping 2001341 word types\n",
      "2018-11-18 19:37:22,474 : INFO : PROGRESS: at sentence #1920000, processed 51686939 words, keeping 2011614 word types\n",
      "2018-11-18 19:37:22,522 : INFO : PROGRESS: at sentence #1930000, processed 51961418 words, keeping 2019041 word types\n",
      "2018-11-18 19:37:22,572 : INFO : PROGRESS: at sentence #1940000, processed 52232741 words, keeping 2025900 word types\n",
      "2018-11-18 19:37:22,617 : INFO : PROGRESS: at sentence #1950000, processed 52483190 words, keeping 2033975 word types\n",
      "2018-11-18 19:37:22,661 : INFO : PROGRESS: at sentence #1960000, processed 52731686 words, keeping 2040416 word types\n",
      "2018-11-18 19:37:22,707 : INFO : PROGRESS: at sentence #1970000, processed 52989268 words, keeping 2047718 word types\n",
      "2018-11-18 19:37:22,753 : INFO : PROGRESS: at sentence #1980000, processed 53257455 words, keeping 2054363 word types\n",
      "2018-11-18 19:37:22,801 : INFO : PROGRESS: at sentence #1990000, processed 53533863 words, keeping 2061624 word types\n",
      "2018-11-18 19:37:22,849 : INFO : PROGRESS: at sentence #2000000, processed 53804174 words, keeping 2069250 word types\n",
      "2018-11-18 19:37:22,898 : INFO : PROGRESS: at sentence #2010000, processed 54067539 words, keeping 2077671 word types\n",
      "2018-11-18 19:37:22,951 : INFO : PROGRESS: at sentence #2020000, processed 54346171 words, keeping 2086163 word types\n",
      "2018-11-18 19:37:23,004 : INFO : PROGRESS: at sentence #2030000, processed 54623316 words, keeping 2094247 word types\n",
      "2018-11-18 19:37:23,058 : INFO : PROGRESS: at sentence #2040000, processed 54899511 words, keeping 2102948 word types\n",
      "2018-11-18 19:37:23,104 : INFO : PROGRESS: at sentence #2050000, processed 55147599 words, keeping 2109229 word types\n",
      "2018-11-18 19:37:23,158 : INFO : PROGRESS: at sentence #2060000, processed 55416274 words, keeping 2119318 word types\n",
      "2018-11-18 19:37:23,209 : INFO : PROGRESS: at sentence #2070000, processed 55679574 words, keeping 2126347 word types\n",
      "2018-11-18 19:37:23,266 : INFO : PROGRESS: at sentence #2080000, processed 55970292 words, keeping 2133272 word types\n",
      "2018-11-18 19:37:23,319 : INFO : PROGRESS: at sentence #2090000, processed 56238200 words, keeping 2142170 word types\n",
      "2018-11-18 19:37:23,367 : INFO : PROGRESS: at sentence #2100000, processed 56508195 words, keeping 2147665 word types\n",
      "2018-11-18 19:37:23,420 : INFO : PROGRESS: at sentence #2110000, processed 56784037 words, keeping 2155563 word types\n",
      "2018-11-18 19:37:23,468 : INFO : PROGRESS: at sentence #2120000, processed 57043001 words, keeping 2162552 word types\n",
      "2018-11-18 19:37:23,519 : INFO : PROGRESS: at sentence #2130000, processed 57304905 words, keeping 2170142 word types\n",
      "2018-11-18 19:37:23,569 : INFO : PROGRESS: at sentence #2140000, processed 57571668 words, keeping 2176527 word types\n",
      "2018-11-18 19:37:23,625 : INFO : PROGRESS: at sentence #2150000, processed 57850649 words, keeping 2186747 word types\n",
      "2018-11-18 19:37:23,680 : INFO : PROGRESS: at sentence #2160000, processed 58121932 words, keeping 2197755 word types\n",
      "2018-11-18 19:37:23,726 : INFO : PROGRESS: at sentence #2170000, processed 58371342 words, keeping 2203686 word types\n",
      "2018-11-18 19:37:23,779 : INFO : PROGRESS: at sentence #2180000, processed 58636019 words, keeping 2210434 word types\n",
      "2018-11-18 19:37:23,829 : INFO : PROGRESS: at sentence #2190000, processed 58899683 words, keeping 2217471 word types\n",
      "2018-11-18 19:37:23,882 : INFO : PROGRESS: at sentence #2200000, processed 59170042 words, keeping 2224979 word types\n",
      "2018-11-18 19:37:23,933 : INFO : PROGRESS: at sentence #2210000, processed 59443377 words, keeping 2231921 word types\n",
      "2018-11-18 19:37:23,987 : INFO : PROGRESS: at sentence #2220000, processed 59726229 words, keeping 2240913 word types\n",
      "2018-11-18 19:37:24,039 : INFO : PROGRESS: at sentence #2230000, processed 59988632 words, keeping 2247919 word types\n",
      "2018-11-18 19:37:24,091 : INFO : PROGRESS: at sentence #2240000, processed 60259708 words, keeping 2257716 word types\n",
      "2018-11-18 19:37:24,148 : INFO : PROGRESS: at sentence #2250000, processed 60544836 words, keeping 2263832 word types\n",
      "2018-11-18 19:37:24,201 : INFO : PROGRESS: at sentence #2260000, processed 60831802 words, keeping 2271205 word types\n",
      "2018-11-18 19:37:24,248 : INFO : PROGRESS: at sentence #2270000, processed 61095885 words, keeping 2277855 word types\n",
      "2018-11-18 19:37:24,299 : INFO : PROGRESS: at sentence #2280000, processed 61371181 words, keeping 2285512 word types\n",
      "2018-11-18 19:37:24,350 : INFO : PROGRESS: at sentence #2290000, processed 61647076 words, keeping 2293939 word types\n",
      "2018-11-18 19:37:24,402 : INFO : PROGRESS: at sentence #2300000, processed 61929773 words, keeping 2304177 word types\n",
      "2018-11-18 19:37:24,454 : INFO : PROGRESS: at sentence #2310000, processed 62228368 words, keeping 2313295 word types\n",
      "2018-11-18 19:37:24,507 : INFO : PROGRESS: at sentence #2320000, processed 62512468 words, keeping 2320785 word types\n",
      "2018-11-18 19:37:24,557 : INFO : PROGRESS: at sentence #2330000, processed 62799850 words, keeping 2328705 word types\n",
      "2018-11-18 19:37:24,608 : INFO : PROGRESS: at sentence #2340000, processed 63084001 words, keeping 2336337 word types\n",
      "2018-11-18 19:37:24,658 : INFO : PROGRESS: at sentence #2350000, processed 63359466 words, keeping 2342870 word types\n",
      "2018-11-18 19:37:24,706 : INFO : PROGRESS: at sentence #2360000, processed 63620465 words, keeping 2349070 word types\n",
      "2018-11-18 19:37:24,758 : INFO : PROGRESS: at sentence #2370000, processed 63897519 words, keeping 2356803 word types\n",
      "2018-11-18 19:37:24,809 : INFO : PROGRESS: at sentence #2380000, processed 64166064 words, keeping 2366806 word types\n",
      "2018-11-18 19:37:24,861 : INFO : PROGRESS: at sentence #2390000, processed 64449529 words, keeping 2375401 word types\n",
      "2018-11-18 19:37:24,909 : INFO : PROGRESS: at sentence #2400000, processed 64722117 words, keeping 2381207 word types\n",
      "2018-11-18 19:37:24,954 : INFO : PROGRESS: at sentence #2410000, processed 64977901 words, keeping 2388816 word types\n",
      "2018-11-18 19:37:25,003 : INFO : PROGRESS: at sentence #2420000, processed 65255122 words, keeping 2395746 word types\n",
      "2018-11-18 19:37:25,052 : INFO : PROGRESS: at sentence #2430000, processed 65511946 words, keeping 2402467 word types\n",
      "2018-11-18 19:37:25,100 : INFO : PROGRESS: at sentence #2440000, processed 65774050 words, keeping 2408826 word types\n",
      "2018-11-18 19:37:25,150 : INFO : PROGRESS: at sentence #2450000, processed 66029273 words, keeping 2415405 word types\n",
      "2018-11-18 19:37:25,200 : INFO : PROGRESS: at sentence #2460000, processed 66303675 words, keeping 2421355 word types\n",
      "2018-11-18 19:37:25,255 : INFO : PROGRESS: at sentence #2470000, processed 66579857 words, keeping 2430402 word types\n",
      "2018-11-18 19:37:25,301 : INFO : PROGRESS: at sentence #2480000, processed 66848130 words, keeping 2437285 word types\n",
      "2018-11-18 19:37:25,353 : INFO : PROGRESS: at sentence #2490000, processed 67126802 words, keeping 2447799 word types\n",
      "2018-11-18 19:37:25,403 : INFO : PROGRESS: at sentence #2500000, processed 67397478 words, keeping 2454384 word types\n",
      "2018-11-18 19:37:25,453 : INFO : PROGRESS: at sentence #2510000, processed 67672343 words, keeping 2462142 word types\n",
      "2018-11-18 19:37:25,503 : INFO : PROGRESS: at sentence #2520000, processed 67945140 words, keeping 2468648 word types\n",
      "2018-11-18 19:37:25,553 : INFO : PROGRESS: at sentence #2530000, processed 68204426 words, keeping 2478614 word types\n",
      "2018-11-18 19:37:25,602 : INFO : PROGRESS: at sentence #2540000, processed 68474814 words, keeping 2485289 word types\n",
      "2018-11-18 19:37:25,651 : INFO : PROGRESS: at sentence #2550000, processed 68733194 words, keeping 2493919 word types\n",
      "2018-11-18 19:37:25,699 : INFO : PROGRESS: at sentence #2560000, processed 68984780 words, keeping 2504722 word types\n",
      "2018-11-18 19:37:25,748 : INFO : PROGRESS: at sentence #2570000, processed 69261522 words, keeping 2511204 word types\n",
      "2018-11-18 19:37:25,798 : INFO : PROGRESS: at sentence #2580000, processed 69505548 words, keeping 2523306 word types\n",
      "2018-11-18 19:37:25,848 : INFO : PROGRESS: at sentence #2590000, processed 69790986 words, keeping 2530687 word types\n",
      "2018-11-18 19:37:25,898 : INFO : PROGRESS: at sentence #2600000, processed 70066058 words, keeping 2538151 word types\n",
      "2018-11-18 19:37:25,947 : INFO : PROGRESS: at sentence #2610000, processed 70328026 words, keeping 2544402 word types\n",
      "2018-11-18 19:37:25,997 : INFO : PROGRESS: at sentence #2620000, processed 70599972 words, keeping 2552893 word types\n",
      "2018-11-18 19:37:26,047 : INFO : PROGRESS: at sentence #2630000, processed 70859697 words, keeping 2560457 word types\n",
      "2018-11-18 19:37:26,102 : INFO : PROGRESS: at sentence #2640000, processed 71149796 words, keeping 2568580 word types\n",
      "2018-11-18 19:37:26,158 : INFO : PROGRESS: at sentence #2650000, processed 71432230 words, keeping 2576399 word types\n",
      "2018-11-18 19:37:26,206 : INFO : PROGRESS: at sentence #2660000, processed 71694236 words, keeping 2582576 word types\n",
      "2018-11-18 19:37:26,254 : INFO : PROGRESS: at sentence #2670000, processed 71958669 words, keeping 2589712 word types\n",
      "2018-11-18 19:37:26,302 : INFO : PROGRESS: at sentence #2680000, processed 72215743 words, keeping 2596573 word types\n",
      "2018-11-18 19:37:26,349 : INFO : PROGRESS: at sentence #2690000, processed 72473868 words, keeping 2603888 word types\n",
      "2018-11-18 19:37:26,394 : INFO : PROGRESS: at sentence #2700000, processed 72734405 words, keeping 2609355 word types\n",
      "2018-11-18 19:37:26,442 : INFO : PROGRESS: at sentence #2710000, processed 73001403 words, keeping 2615925 word types\n",
      "2018-11-18 19:37:26,490 : INFO : PROGRESS: at sentence #2720000, processed 73275272 words, keeping 2621785 word types\n",
      "2018-11-18 19:37:26,543 : INFO : PROGRESS: at sentence #2730000, processed 73561392 words, keeping 2629833 word types\n",
      "2018-11-18 19:37:26,596 : INFO : PROGRESS: at sentence #2740000, processed 73848134 words, keeping 2636242 word types\n",
      "2018-11-18 19:37:26,645 : INFO : PROGRESS: at sentence #2750000, processed 74100273 words, keeping 2643152 word types\n",
      "2018-11-18 19:37:26,695 : INFO : PROGRESS: at sentence #2760000, processed 74362521 words, keeping 2649788 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-18 19:37:26,750 : INFO : PROGRESS: at sentence #2770000, processed 74648872 words, keeping 2664586 word types\n",
      "2018-11-18 19:37:26,802 : INFO : PROGRESS: at sentence #2780000, processed 74937389 words, keeping 2672401 word types\n",
      "2018-11-18 19:37:26,850 : INFO : PROGRESS: at sentence #2790000, processed 75196085 words, keeping 2678742 word types\n",
      "2018-11-18 19:37:26,900 : INFO : PROGRESS: at sentence #2800000, processed 75461966 words, keeping 2686681 word types\n",
      "2018-11-18 19:37:26,948 : INFO : PROGRESS: at sentence #2810000, processed 75732601 words, keeping 2693191 word types\n",
      "2018-11-18 19:37:26,998 : INFO : PROGRESS: at sentence #2820000, processed 76001138 words, keeping 2700068 word types\n",
      "2018-11-18 19:37:27,043 : INFO : PROGRESS: at sentence #2830000, processed 76225628 words, keeping 2705968 word types\n",
      "2018-11-18 19:37:27,095 : INFO : PROGRESS: at sentence #2840000, processed 76499684 words, keeping 2714152 word types\n",
      "2018-11-18 19:37:27,151 : INFO : PROGRESS: at sentence #2850000, processed 76769290 words, keeping 2723002 word types\n",
      "2018-11-18 19:37:27,199 : INFO : PROGRESS: at sentence #2860000, processed 77035193 words, keeping 2728752 word types\n",
      "2018-11-18 19:37:27,249 : INFO : PROGRESS: at sentence #2870000, processed 77304937 words, keeping 2735750 word types\n",
      "2018-11-18 19:37:27,300 : INFO : PROGRESS: at sentence #2880000, processed 77585706 words, keeping 2742583 word types\n",
      "2018-11-18 19:37:27,353 : INFO : PROGRESS: at sentence #2890000, processed 77849437 words, keeping 2753946 word types\n",
      "2018-11-18 19:37:27,398 : INFO : PROGRESS: at sentence #2900000, processed 78094595 words, keeping 2759554 word types\n",
      "2018-11-18 19:37:27,452 : INFO : PROGRESS: at sentence #2910000, processed 78371467 words, keeping 2771680 word types\n",
      "2018-11-18 19:37:27,505 : INFO : PROGRESS: at sentence #2920000, processed 78648296 words, keeping 2780202 word types\n",
      "2018-11-18 19:37:27,556 : INFO : PROGRESS: at sentence #2930000, processed 78928249 words, keeping 2790812 word types\n",
      "2018-11-18 19:37:27,754 : INFO : PROGRESS: at sentence #2940000, processed 79200881 words, keeping 2799602 word types\n",
      "2018-11-18 19:37:27,800 : INFO : PROGRESS: at sentence #2950000, processed 79463084 words, keeping 2806626 word types\n",
      "2018-11-18 19:37:27,849 : INFO : PROGRESS: at sentence #2960000, processed 79727602 words, keeping 2815154 word types\n",
      "2018-11-18 19:37:27,896 : INFO : PROGRESS: at sentence #2970000, processed 79994967 words, keeping 2825023 word types\n",
      "2018-11-18 19:37:27,942 : INFO : PROGRESS: at sentence #2980000, processed 80263641 words, keeping 2832946 word types\n",
      "2018-11-18 19:37:27,990 : INFO : PROGRESS: at sentence #2990000, processed 80531390 words, keeping 2839349 word types\n",
      "2018-11-18 19:37:28,054 : INFO : PROGRESS: at sentence #3000000, processed 80823436 words, keeping 2848155 word types\n",
      "2018-11-18 19:37:28,103 : INFO : PROGRESS: at sentence #3010000, processed 81098886 words, keeping 2857370 word types\n",
      "2018-11-18 19:37:28,151 : INFO : PROGRESS: at sentence #3020000, processed 81366623 words, keeping 2863317 word types\n",
      "2018-11-18 19:37:28,201 : INFO : PROGRESS: at sentence #3030000, processed 81643666 words, keeping 2870523 word types\n",
      "2018-11-18 19:37:28,250 : INFO : PROGRESS: at sentence #3040000, processed 81909709 words, keeping 2879259 word types\n",
      "2018-11-18 19:37:28,295 : INFO : PROGRESS: at sentence #3050000, processed 82166588 words, keeping 2884687 word types\n",
      "2018-11-18 19:37:28,346 : INFO : PROGRESS: at sentence #3060000, processed 82455858 words, keeping 2890391 word types\n",
      "2018-11-18 19:37:28,400 : INFO : PROGRESS: at sentence #3070000, processed 82751476 words, keeping 2899729 word types\n",
      "2018-11-18 19:37:28,448 : INFO : PROGRESS: at sentence #3080000, processed 83021110 words, keeping 2907899 word types\n",
      "2018-11-18 19:37:28,499 : INFO : PROGRESS: at sentence #3090000, processed 83311215 words, keeping 2915146 word types\n",
      "2018-11-18 19:37:28,544 : INFO : PROGRESS: at sentence #3100000, processed 83557954 words, keeping 2920618 word types\n",
      "2018-11-18 19:37:28,594 : INFO : PROGRESS: at sentence #3110000, processed 83823769 words, keeping 2927276 word types\n",
      "2018-11-18 19:37:28,638 : INFO : PROGRESS: at sentence #3120000, processed 84076950 words, keeping 2931769 word types\n",
      "2018-11-18 19:37:28,689 : INFO : PROGRESS: at sentence #3130000, processed 84355816 words, keeping 2941738 word types\n",
      "2018-11-18 19:37:28,736 : INFO : PROGRESS: at sentence #3140000, processed 84614789 words, keeping 2949542 word types\n",
      "2018-11-18 19:37:28,783 : INFO : PROGRESS: at sentence #3150000, processed 84872819 words, keeping 2955062 word types\n",
      "2018-11-18 19:37:28,829 : INFO : PROGRESS: at sentence #3160000, processed 85139737 words, keeping 2960573 word types\n",
      "2018-11-18 19:37:28,877 : INFO : PROGRESS: at sentence #3170000, processed 85412022 words, keeping 2966392 word types\n",
      "2018-11-18 19:37:28,930 : INFO : PROGRESS: at sentence #3180000, processed 85701327 words, keeping 2975433 word types\n",
      "2018-11-18 19:37:28,976 : INFO : PROGRESS: at sentence #3190000, processed 85959386 words, keeping 2981645 word types\n",
      "2018-11-18 19:37:29,025 : INFO : PROGRESS: at sentence #3200000, processed 86218288 words, keeping 2988529 word types\n",
      "2018-11-18 19:37:29,077 : INFO : PROGRESS: at sentence #3210000, processed 86494650 words, keeping 2995212 word types\n",
      "2018-11-18 19:37:29,128 : INFO : PROGRESS: at sentence #3220000, processed 86769355 words, keeping 3004978 word types\n",
      "2018-11-18 19:37:29,178 : INFO : PROGRESS: at sentence #3230000, processed 87053708 words, keeping 3011538 word types\n",
      "2018-11-18 19:37:29,225 : INFO : PROGRESS: at sentence #3240000, processed 87310207 words, keeping 3021902 word types\n",
      "2018-11-18 19:37:29,276 : INFO : PROGRESS: at sentence #3250000, processed 87590496 words, keeping 3029067 word types\n",
      "2018-11-18 19:37:29,323 : INFO : PROGRESS: at sentence #3260000, processed 87854382 words, keeping 3034849 word types\n",
      "2018-11-18 19:37:29,372 : INFO : PROGRESS: at sentence #3270000, processed 88128469 words, keeping 3042107 word types\n",
      "2018-11-18 19:37:29,418 : INFO : PROGRESS: at sentence #3280000, processed 88375307 words, keeping 3050033 word types\n",
      "2018-11-18 19:37:29,467 : INFO : PROGRESS: at sentence #3290000, processed 88645822 words, keeping 3056581 word types\n",
      "2018-11-18 19:37:29,518 : INFO : PROGRESS: at sentence #3300000, processed 88919653 words, keeping 3065435 word types\n",
      "2018-11-18 19:37:29,565 : INFO : PROGRESS: at sentence #3310000, processed 89186883 words, keeping 3071740 word types\n",
      "2018-11-18 19:37:29,615 : INFO : PROGRESS: at sentence #3320000, processed 89465693 words, keeping 3079206 word types\n",
      "2018-11-18 19:37:29,661 : INFO : PROGRESS: at sentence #3330000, processed 89725633 words, keeping 3085726 word types\n",
      "2018-11-18 19:37:29,714 : INFO : PROGRESS: at sentence #3340000, processed 90020037 words, keeping 3093137 word types\n",
      "2018-11-18 19:37:29,765 : INFO : PROGRESS: at sentence #3350000, processed 90285569 words, keeping 3102848 word types\n",
      "2018-11-18 19:37:29,809 : INFO : PROGRESS: at sentence #3360000, processed 90528290 words, keeping 3109631 word types\n",
      "2018-11-18 19:37:29,858 : INFO : PROGRESS: at sentence #3370000, processed 90805083 words, keeping 3116248 word types\n",
      "2018-11-18 19:37:29,903 : INFO : PROGRESS: at sentence #3380000, processed 91071445 words, keeping 3123109 word types\n",
      "2018-11-18 19:37:29,949 : INFO : PROGRESS: at sentence #3390000, processed 91331222 words, keeping 3131103 word types\n",
      "2018-11-18 19:37:29,999 : INFO : PROGRESS: at sentence #3400000, processed 91609238 words, keeping 3137696 word types\n",
      "2018-11-18 19:37:30,049 : INFO : PROGRESS: at sentence #3410000, processed 91868409 words, keeping 3147120 word types\n",
      "2018-11-18 19:37:30,101 : INFO : PROGRESS: at sentence #3420000, processed 92151149 words, keeping 3153504 word types\n",
      "2018-11-18 19:37:30,153 : INFO : PROGRESS: at sentence #3430000, processed 92430037 words, keeping 3159536 word types\n",
      "2018-11-18 19:37:30,195 : INFO : PROGRESS: at sentence #3440000, processed 92660935 words, keeping 3165715 word types\n",
      "2018-11-18 19:37:30,248 : INFO : PROGRESS: at sentence #3450000, processed 92940362 words, keeping 3178052 word types\n",
      "2018-11-18 19:37:30,299 : INFO : PROGRESS: at sentence #3460000, processed 93219281 words, keeping 3186955 word types\n",
      "2018-11-18 19:37:30,346 : INFO : PROGRESS: at sentence #3470000, processed 93477841 words, keeping 3193573 word types\n",
      "2018-11-18 19:37:30,396 : INFO : PROGRESS: at sentence #3480000, processed 93745577 words, keeping 3199553 word types\n",
      "2018-11-18 19:37:30,437 : INFO : PROGRESS: at sentence #3490000, processed 93954576 words, keeping 3207772 word types\n",
      "2018-11-18 19:37:30,486 : INFO : PROGRESS: at sentence #3500000, processed 94226419 words, keeping 3214598 word types\n",
      "2018-11-18 19:37:30,531 : INFO : PROGRESS: at sentence #3510000, processed 94486363 words, keeping 3221343 word types\n",
      "2018-11-18 19:37:30,578 : INFO : PROGRESS: at sentence #3520000, processed 94756812 words, keeping 3227003 word types\n",
      "2018-11-18 19:37:30,620 : INFO : PROGRESS: at sentence #3530000, processed 94998473 words, keeping 3231780 word types\n",
      "2018-11-18 19:37:30,667 : INFO : PROGRESS: at sentence #3540000, processed 95264264 words, keeping 3237945 word types\n",
      "2018-11-18 19:37:30,716 : INFO : PROGRESS: at sentence #3550000, processed 95536088 words, keeping 3244552 word types\n",
      "2018-11-18 19:37:30,760 : INFO : PROGRESS: at sentence #3560000, processed 95787576 words, keeping 3250562 word types\n",
      "2018-11-18 19:37:30,807 : INFO : PROGRESS: at sentence #3570000, processed 96049027 words, keeping 3257987 word types\n",
      "2018-11-18 19:37:30,857 : INFO : PROGRESS: at sentence #3580000, processed 96298220 words, keeping 3268599 word types\n",
      "2018-11-18 19:37:30,893 : INFO : PROGRESS: at sentence #3590000, processed 96479312 words, keeping 3279305 word types\n",
      "2018-11-18 19:37:30,942 : INFO : PROGRESS: at sentence #3600000, processed 96754381 words, keeping 3286378 word types\n",
      "2018-11-18 19:37:30,990 : INFO : PROGRESS: at sentence #3610000, processed 97026174 words, keeping 3292329 word types\n",
      "2018-11-18 19:37:31,044 : INFO : PROGRESS: at sentence #3620000, processed 97298423 words, keeping 3300270 word types\n",
      "2018-11-18 19:37:31,089 : INFO : PROGRESS: at sentence #3630000, processed 97548478 words, keeping 3306159 word types\n",
      "2018-11-18 19:37:31,140 : INFO : PROGRESS: at sentence #3640000, processed 97820875 words, keeping 3314062 word types\n",
      "2018-11-18 19:37:31,185 : INFO : PROGRESS: at sentence #3650000, processed 98076873 words, keeping 3319338 word types\n",
      "2018-11-18 19:37:31,234 : INFO : PROGRESS: at sentence #3660000, processed 98335133 words, keeping 3327453 word types\n",
      "2018-11-18 19:37:31,281 : INFO : PROGRESS: at sentence #3670000, processed 98584478 words, keeping 3335100 word types\n",
      "2018-11-18 19:37:31,330 : INFO : PROGRESS: at sentence #3680000, processed 98856167 words, keeping 3342556 word types\n",
      "2018-11-18 19:37:31,378 : INFO : PROGRESS: at sentence #3690000, processed 99133004 words, keeping 3348281 word types\n",
      "2018-11-18 19:37:31,429 : INFO : PROGRESS: at sentence #3700000, processed 99412693 words, keeping 3355195 word types\n",
      "2018-11-18 19:37:31,481 : INFO : PROGRESS: at sentence #3710000, processed 99677375 words, keeping 3363468 word types\n",
      "2018-11-18 19:37:31,532 : INFO : PROGRESS: at sentence #3720000, processed 99938419 words, keeping 3369911 word types\n",
      "2018-11-18 19:37:31,586 : INFO : PROGRESS: at sentence #3730000, processed 100218452 words, keeping 3375633 word types\n",
      "2018-11-18 19:37:31,645 : INFO : PROGRESS: at sentence #3740000, processed 100521871 words, keeping 3383808 word types\n",
      "2018-11-18 19:37:31,707 : INFO : PROGRESS: at sentence #3750000, processed 100840343 words, keeping 3392591 word types\n",
      "2018-11-18 19:37:31,760 : INFO : PROGRESS: at sentence #3760000, processed 101108382 words, keeping 3398478 word types\n",
      "2018-11-18 19:37:31,816 : INFO : PROGRESS: at sentence #3770000, processed 101389262 words, keeping 3405242 word types\n",
      "2018-11-18 19:37:31,869 : INFO : PROGRESS: at sentence #3780000, processed 101662605 words, keeping 3411611 word types\n",
      "2018-11-18 19:37:31,926 : INFO : PROGRESS: at sentence #3790000, processed 101936522 words, keeping 3421562 word types\n",
      "2018-11-18 19:37:31,980 : INFO : PROGRESS: at sentence #3800000, processed 102205274 words, keeping 3428267 word types\n",
      "2018-11-18 19:37:32,041 : INFO : PROGRESS: at sentence #3810000, processed 102507790 words, keeping 3435455 word types\n",
      "2018-11-18 19:37:32,096 : INFO : PROGRESS: at sentence #3820000, processed 102774112 words, keeping 3445538 word types\n",
      "2018-11-18 19:37:32,152 : INFO : PROGRESS: at sentence #3830000, processed 103047604 words, keeping 3452295 word types\n",
      "2018-11-18 19:37:32,212 : INFO : PROGRESS: at sentence #3840000, processed 103366710 words, keeping 3459774 word types\n",
      "2018-11-18 19:37:32,264 : INFO : PROGRESS: at sentence #3850000, processed 103634199 words, keeping 3466231 word types\n",
      "2018-11-18 19:37:32,316 : INFO : PROGRESS: at sentence #3860000, processed 103898019 words, keeping 3472419 word types\n",
      "2018-11-18 19:37:32,375 : INFO : PROGRESS: at sentence #3870000, processed 104190771 words, keeping 3480602 word types\n",
      "2018-11-18 19:37:32,433 : INFO : PROGRESS: at sentence #3880000, processed 104483409 words, keeping 3488915 word types\n",
      "2018-11-18 19:37:32,489 : INFO : PROGRESS: at sentence #3890000, processed 104774525 words, keeping 3495304 word types\n",
      "2018-11-18 19:37:32,544 : INFO : PROGRESS: at sentence #3900000, processed 105051852 words, keeping 3500944 word types\n",
      "2018-11-18 19:37:32,600 : INFO : PROGRESS: at sentence #3910000, processed 105336475 words, keeping 3507137 word types\n",
      "2018-11-18 19:37:32,657 : INFO : PROGRESS: at sentence #3920000, processed 105621077 words, keeping 3515512 word types\n",
      "2018-11-18 19:37:32,714 : INFO : PROGRESS: at sentence #3930000, processed 105891593 words, keeping 3523224 word types\n",
      "2018-11-18 19:37:32,773 : INFO : PROGRESS: at sentence #3940000, processed 106193618 words, keeping 3531274 word types\n",
      "2018-11-18 19:37:32,826 : INFO : PROGRESS: at sentence #3950000, processed 106461121 words, keeping 3537456 word types\n",
      "2018-11-18 19:37:32,887 : INFO : PROGRESS: at sentence #3960000, processed 106761424 words, keeping 3544645 word types\n",
      "2018-11-18 19:37:32,942 : INFO : PROGRESS: at sentence #3970000, processed 107022901 words, keeping 3554480 word types\n",
      "2018-11-18 19:37:32,997 : INFO : PROGRESS: at sentence #3980000, processed 107291512 words, keeping 3561020 word types\n",
      "2018-11-18 19:37:33,056 : INFO : PROGRESS: at sentence #3990000, processed 107568190 words, keeping 3568314 word types\n",
      "2018-11-18 19:37:33,111 : INFO : PROGRESS: at sentence #4000000, processed 107847433 words, keeping 3573914 word types\n",
      "2018-11-18 19:37:33,164 : INFO : PROGRESS: at sentence #4010000, processed 108117834 words, keeping 3579950 word types\n",
      "2018-11-18 19:37:33,221 : INFO : PROGRESS: at sentence #4020000, processed 108409822 words, keeping 3588148 word types\n",
      "2018-11-18 19:37:33,280 : INFO : PROGRESS: at sentence #4030000, processed 108709675 words, keeping 3596042 word types\n",
      "2018-11-18 19:37:33,335 : INFO : PROGRESS: at sentence #4040000, processed 108980845 words, keeping 3602080 word types\n",
      "2018-11-18 19:37:33,395 : INFO : PROGRESS: at sentence #4050000, processed 109288906 words, keeping 3609288 word types\n",
      "2018-11-18 19:37:33,449 : INFO : PROGRESS: at sentence #4060000, processed 109546071 words, keeping 3617726 word types\n",
      "2018-11-18 19:37:33,508 : INFO : PROGRESS: at sentence #4070000, processed 109840904 words, keeping 3623951 word types\n",
      "2018-11-18 19:37:33,569 : INFO : PROGRESS: at sentence #4080000, processed 110133697 words, keeping 3632362 word types\n",
      "2018-11-18 19:37:33,626 : INFO : PROGRESS: at sentence #4090000, processed 110410503 words, keeping 3639827 word types\n",
      "2018-11-18 19:37:33,685 : INFO : PROGRESS: at sentence #4100000, processed 110688058 words, keeping 3647124 word types\n",
      "2018-11-18 19:37:33,749 : INFO : PROGRESS: at sentence #4110000, processed 110981916 words, keeping 3654149 word types\n",
      "2018-11-18 19:37:33,806 : INFO : PROGRESS: at sentence #4120000, processed 111268620 words, keeping 3661760 word types\n",
      "2018-11-18 19:37:33,867 : INFO : PROGRESS: at sentence #4130000, processed 111561039 words, keeping 3670502 word types\n",
      "2018-11-18 19:37:33,920 : INFO : PROGRESS: at sentence #4140000, processed 111826533 words, keeping 3677332 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-18 19:37:33,974 : INFO : PROGRESS: at sentence #4150000, processed 112089450 words, keeping 3683572 word types\n",
      "2018-11-18 19:37:34,029 : INFO : PROGRESS: at sentence #4160000, processed 112361513 words, keeping 3689759 word types\n",
      "2018-11-18 19:37:34,092 : INFO : PROGRESS: at sentence #4170000, processed 112660755 words, keeping 3697326 word types\n",
      "2018-11-18 19:37:34,149 : INFO : PROGRESS: at sentence #4180000, processed 112929075 words, keeping 3702165 word types\n",
      "2018-11-18 19:37:34,206 : INFO : PROGRESS: at sentence #4190000, processed 113207009 words, keeping 3709796 word types\n",
      "2018-11-18 19:37:34,261 : INFO : PROGRESS: at sentence #4200000, processed 113481582 words, keeping 3717773 word types\n",
      "2018-11-18 19:37:34,320 : INFO : PROGRESS: at sentence #4210000, processed 113786893 words, keeping 3725785 word types\n",
      "2018-11-18 19:37:34,375 : INFO : PROGRESS: at sentence #4220000, processed 114077964 words, keeping 3732043 word types\n",
      "2018-11-18 19:37:34,433 : INFO : PROGRESS: at sentence #4230000, processed 114365639 words, keeping 3739395 word types\n",
      "2018-11-18 19:37:34,489 : INFO : PROGRESS: at sentence #4240000, processed 114654120 words, keeping 3746330 word types\n",
      "2018-11-18 19:37:34,546 : INFO : PROGRESS: at sentence #4250000, processed 114934001 words, keeping 3754680 word types\n",
      "2018-11-18 19:37:34,598 : INFO : PROGRESS: at sentence #4260000, processed 115187539 words, keeping 3761902 word types\n",
      "2018-11-18 19:37:34,648 : INFO : PROGRESS: at sentence #4270000, processed 115441360 words, keeping 3767503 word types\n",
      "2018-11-18 19:37:34,703 : INFO : PROGRESS: at sentence #4280000, processed 115707674 words, keeping 3775197 word types\n",
      "2018-11-18 19:37:34,758 : INFO : PROGRESS: at sentence #4290000, processed 115981365 words, keeping 3781792 word types\n",
      "2018-11-18 19:37:34,813 : INFO : PROGRESS: at sentence #4300000, processed 116258891 words, keeping 3789132 word types\n",
      "2018-11-18 19:37:34,871 : INFO : PROGRESS: at sentence #4310000, processed 116556088 words, keeping 3797998 word types\n",
      "2018-11-18 19:37:34,925 : INFO : PROGRESS: at sentence #4320000, processed 116833189 words, keeping 3803440 word types\n",
      "2018-11-18 19:37:34,980 : INFO : PROGRESS: at sentence #4330000, processed 117104203 words, keeping 3810455 word types\n",
      "2018-11-18 19:37:35,038 : INFO : PROGRESS: at sentence #4340000, processed 117390794 words, keeping 3819542 word types\n",
      "2018-11-18 19:37:35,091 : INFO : PROGRESS: at sentence #4350000, processed 117663591 words, keeping 3828097 word types\n",
      "2018-11-18 19:37:35,149 : INFO : PROGRESS: at sentence #4360000, processed 117937152 words, keeping 3833812 word types\n",
      "2018-11-18 19:37:35,207 : INFO : PROGRESS: at sentence #4370000, processed 118233468 words, keeping 3840557 word types\n",
      "2018-11-18 19:37:35,265 : INFO : PROGRESS: at sentence #4380000, processed 118517208 words, keeping 3847326 word types\n",
      "2018-11-18 19:37:35,317 : INFO : PROGRESS: at sentence #4390000, processed 118757220 words, keeping 3856099 word types\n",
      "2018-11-18 19:37:35,373 : INFO : PROGRESS: at sentence #4400000, processed 119040010 words, keeping 3865812 word types\n",
      "2018-11-18 19:37:35,428 : INFO : PROGRESS: at sentence #4410000, processed 119321589 words, keeping 3871836 word types\n",
      "2018-11-18 19:37:35,490 : INFO : PROGRESS: at sentence #4420000, processed 119616975 words, keeping 3882858 word types\n",
      "2018-11-18 19:37:35,546 : INFO : PROGRESS: at sentence #4430000, processed 119898153 words, keeping 3888825 word types\n",
      "2018-11-18 19:37:35,603 : INFO : PROGRESS: at sentence #4440000, processed 120186481 words, keeping 3896449 word types\n",
      "2018-11-18 19:37:35,663 : INFO : PROGRESS: at sentence #4450000, processed 120472102 words, keeping 3908486 word types\n",
      "2018-11-18 19:37:35,723 : INFO : PROGRESS: at sentence #4460000, processed 120758636 words, keeping 3916599 word types\n",
      "2018-11-18 19:37:35,775 : INFO : PROGRESS: at sentence #4470000, processed 121022643 words, keeping 3922136 word types\n",
      "2018-11-18 19:37:35,835 : INFO : PROGRESS: at sentence #4480000, processed 121316077 words, keeping 3929275 word types\n",
      "2018-11-18 19:37:35,894 : INFO : PROGRESS: at sentence #4490000, processed 121604196 words, keeping 3936568 word types\n",
      "2018-11-18 19:37:35,946 : INFO : PROGRESS: at sentence #4500000, processed 121862965 words, keeping 3942538 word types\n",
      "2018-11-18 19:37:36,002 : INFO : PROGRESS: at sentence #4510000, processed 122114192 words, keeping 3952405 word types\n",
      "2018-11-18 19:37:36,061 : INFO : PROGRESS: at sentence #4520000, processed 122399290 words, keeping 3960448 word types\n",
      "2018-11-18 19:37:36,118 : INFO : PROGRESS: at sentence #4530000, processed 122671490 words, keeping 3965894 word types\n",
      "2018-11-18 19:37:36,176 : INFO : PROGRESS: at sentence #4540000, processed 122948095 words, keeping 3973649 word types\n",
      "2018-11-18 19:37:36,229 : INFO : PROGRESS: at sentence #4550000, processed 123218451 words, keeping 3979522 word types\n",
      "2018-11-18 19:37:36,282 : INFO : PROGRESS: at sentence #4560000, processed 123478942 words, keeping 3985228 word types\n",
      "2018-11-18 19:37:36,341 : INFO : PROGRESS: at sentence #4570000, processed 123764871 words, keeping 3994209 word types\n",
      "2018-11-18 19:37:36,399 : INFO : PROGRESS: at sentence #4580000, processed 124048419 words, keeping 4005272 word types\n",
      "2018-11-18 19:37:36,455 : INFO : PROGRESS: at sentence #4590000, processed 124331869 words, keeping 4012186 word types\n",
      "2018-11-18 19:37:36,508 : INFO : PROGRESS: at sentence #4600000, processed 124606164 words, keeping 4017728 word types\n",
      "2018-11-18 19:37:36,565 : INFO : PROGRESS: at sentence #4610000, processed 124888978 words, keeping 4024266 word types\n",
      "2018-11-18 19:37:36,619 : INFO : PROGRESS: at sentence #4620000, processed 125160023 words, keeping 4029760 word types\n",
      "2018-11-18 19:37:36,674 : INFO : PROGRESS: at sentence #4630000, processed 125434193 words, keeping 4036958 word types\n",
      "2018-11-18 19:37:36,729 : INFO : PROGRESS: at sentence #4640000, processed 125707652 words, keeping 4044238 word types\n",
      "2018-11-18 19:37:36,784 : INFO : PROGRESS: at sentence #4650000, processed 125988560 words, keeping 4052141 word types\n",
      "2018-11-18 19:37:36,840 : INFO : PROGRESS: at sentence #4660000, processed 126275488 words, keeping 4058813 word types\n",
      "2018-11-18 19:37:36,892 : INFO : PROGRESS: at sentence #4670000, processed 126550604 words, keeping 4064873 word types\n",
      "2018-11-18 19:37:36,949 : INFO : PROGRESS: at sentence #4680000, processed 126837584 words, keeping 4073017 word types\n",
      "2018-11-18 19:37:37,006 : INFO : PROGRESS: at sentence #4690000, processed 127113658 words, keeping 4082267 word types\n",
      "2018-11-18 19:37:37,069 : INFO : PROGRESS: at sentence #4700000, processed 127411211 words, keeping 4089782 word types\n",
      "2018-11-18 19:37:37,124 : INFO : PROGRESS: at sentence #4710000, processed 127696460 words, keeping 4096218 word types\n",
      "2018-11-18 19:37:37,185 : INFO : PROGRESS: at sentence #4720000, processed 127985416 words, keeping 4104528 word types\n",
      "2018-11-18 19:37:37,243 : INFO : PROGRESS: at sentence #4730000, processed 128278209 words, keeping 4112631 word types\n",
      "2018-11-18 19:37:37,297 : INFO : PROGRESS: at sentence #4740000, processed 128547359 words, keeping 4122049 word types\n",
      "2018-11-18 19:37:37,356 : INFO : PROGRESS: at sentence #4750000, processed 128830805 words, keeping 4129732 word types\n",
      "2018-11-18 19:37:37,409 : INFO : PROGRESS: at sentence #4760000, processed 129096439 words, keeping 4135948 word types\n",
      "2018-11-18 19:37:37,469 : INFO : PROGRESS: at sentence #4770000, processed 129399810 words, keeping 4144812 word types\n",
      "2018-11-18 19:37:37,526 : INFO : PROGRESS: at sentence #4780000, processed 129682801 words, keeping 4151560 word types\n",
      "2018-11-18 19:37:37,581 : INFO : PROGRESS: at sentence #4790000, processed 129952211 words, keeping 4157989 word types\n",
      "2018-11-18 19:37:37,638 : INFO : PROGRESS: at sentence #4800000, processed 130236678 words, keeping 4164563 word types\n",
      "2018-11-18 19:37:37,691 : INFO : PROGRESS: at sentence #4810000, processed 130505360 words, keeping 4171801 word types\n",
      "2018-11-18 19:37:37,746 : INFO : PROGRESS: at sentence #4820000, processed 130772596 words, keeping 4179995 word types\n",
      "2018-11-18 19:37:37,802 : INFO : PROGRESS: at sentence #4830000, processed 131064654 words, keeping 4186741 word types\n",
      "2018-11-18 19:37:37,863 : INFO : PROGRESS: at sentence #4840000, processed 131361994 words, keeping 4194470 word types\n",
      "2018-11-18 19:37:37,918 : INFO : PROGRESS: at sentence #4850000, processed 131647470 words, keeping 4200307 word types\n",
      "2018-11-18 19:37:37,979 : INFO : PROGRESS: at sentence #4860000, processed 131951378 words, keeping 4209240 word types\n",
      "2018-11-18 19:37:38,039 : INFO : PROGRESS: at sentence #4870000, processed 132245205 words, keeping 4217139 word types\n",
      "2018-11-18 19:37:38,093 : INFO : PROGRESS: at sentence #4880000, processed 132518295 words, keeping 4222824 word types\n",
      "2018-11-18 19:37:38,152 : INFO : PROGRESS: at sentence #4890000, processed 132794909 words, keeping 4228889 word types\n",
      "2018-11-18 19:37:38,208 : INFO : PROGRESS: at sentence #4900000, processed 133077043 words, keeping 4235525 word types\n",
      "2018-11-18 19:37:38,264 : INFO : PROGRESS: at sentence #4910000, processed 133350282 words, keeping 4244207 word types\n",
      "2018-11-18 19:37:38,321 : INFO : PROGRESS: at sentence #4920000, processed 133647047 words, keeping 4250602 word types\n",
      "2018-11-18 19:37:38,371 : INFO : PROGRESS: at sentence #4930000, processed 133896162 words, keeping 4255960 word types\n",
      "2018-11-18 19:37:38,421 : INFO : PROGRESS: at sentence #4940000, processed 134143565 words, keeping 4260608 word types\n",
      "2018-11-18 19:37:38,476 : INFO : PROGRESS: at sentence #4950000, processed 134411589 words, keeping 4267460 word types\n",
      "2018-11-18 19:37:38,535 : INFO : PROGRESS: at sentence #4960000, processed 134708652 words, keeping 4274508 word types\n",
      "2018-11-18 19:37:38,590 : INFO : PROGRESS: at sentence #4970000, processed 134991748 words, keeping 4281361 word types\n",
      "2018-11-18 19:37:38,647 : INFO : PROGRESS: at sentence #4980000, processed 135271492 words, keeping 4287908 word types\n",
      "2018-11-18 19:37:38,705 : INFO : PROGRESS: at sentence #4990000, processed 135555970 words, keeping 4295324 word types\n",
      "2018-11-18 19:37:38,761 : INFO : PROGRESS: at sentence #5000000, processed 135835916 words, keeping 4303565 word types\n",
      "2018-11-18 19:37:38,818 : INFO : PROGRESS: at sentence #5010000, processed 136122939 words, keeping 4310251 word types\n",
      "2018-11-18 19:37:38,877 : INFO : PROGRESS: at sentence #5020000, processed 136410561 words, keeping 4317021 word types\n",
      "2018-11-18 19:37:38,933 : INFO : PROGRESS: at sentence #5030000, processed 136693246 words, keeping 4325804 word types\n",
      "2018-11-18 19:37:38,991 : INFO : PROGRESS: at sentence #5040000, processed 136980710 words, keeping 4333046 word types\n",
      "2018-11-18 19:37:39,051 : INFO : PROGRESS: at sentence #5050000, processed 137262240 words, keeping 4340749 word types\n",
      "2018-11-18 19:37:39,106 : INFO : PROGRESS: at sentence #5060000, processed 137539920 words, keeping 4348335 word types\n",
      "2018-11-18 19:37:39,164 : INFO : PROGRESS: at sentence #5070000, processed 137820018 words, keeping 4355199 word types\n",
      "2018-11-18 19:37:39,219 : INFO : PROGRESS: at sentence #5080000, processed 138096702 words, keeping 4361363 word types\n",
      "2018-11-18 19:37:39,278 : INFO : PROGRESS: at sentence #5090000, processed 138381770 words, keeping 4368616 word types\n",
      "2018-11-18 19:37:39,336 : INFO : PROGRESS: at sentence #5100000, processed 138673489 words, keeping 4379804 word types\n",
      "2018-11-18 19:37:39,394 : INFO : PROGRESS: at sentence #5110000, processed 138962164 words, keeping 4386394 word types\n",
      "2018-11-18 19:37:39,451 : INFO : PROGRESS: at sentence #5120000, processed 139246203 words, keeping 4393310 word types\n",
      "2018-11-18 19:37:39,504 : INFO : PROGRESS: at sentence #5130000, processed 139519511 words, keeping 4399902 word types\n",
      "2018-11-18 19:37:39,559 : INFO : PROGRESS: at sentence #5140000, processed 139798974 words, keeping 4406941 word types\n",
      "2018-11-18 19:37:39,614 : INFO : PROGRESS: at sentence #5150000, processed 140082219 words, keeping 4412859 word types\n",
      "2018-11-18 19:37:39,669 : INFO : PROGRESS: at sentence #5160000, processed 140335561 words, keeping 4423087 word types\n",
      "2018-11-18 19:37:39,724 : INFO : PROGRESS: at sentence #5170000, processed 140598680 words, keeping 4432403 word types\n",
      "2018-11-18 19:37:39,783 : INFO : PROGRESS: at sentence #5180000, processed 140894551 words, keeping 4441572 word types\n",
      "2018-11-18 19:37:39,838 : INFO : PROGRESS: at sentence #5190000, processed 141163447 words, keeping 4450538 word types\n",
      "2018-11-18 19:37:39,893 : INFO : PROGRESS: at sentence #5200000, processed 141440541 words, keeping 4460043 word types\n",
      "2018-11-18 19:37:39,946 : INFO : PROGRESS: at sentence #5210000, processed 141704989 words, keeping 4465236 word types\n",
      "2018-11-18 19:37:40,000 : INFO : PROGRESS: at sentence #5220000, processed 141973270 words, keeping 4471953 word types\n",
      "2018-11-18 19:37:40,058 : INFO : PROGRESS: at sentence #5230000, processed 142260544 words, keeping 4478229 word types\n",
      "2018-11-18 19:37:40,112 : INFO : PROGRESS: at sentence #5240000, processed 142531548 words, keeping 4483500 word types\n",
      "2018-11-18 19:37:40,170 : INFO : PROGRESS: at sentence #5250000, processed 142817542 words, keeping 4489805 word types\n",
      "2018-11-18 19:37:40,225 : INFO : PROGRESS: at sentence #5260000, processed 143105363 words, keeping 4496030 word types\n",
      "2018-11-18 19:37:40,279 : INFO : PROGRESS: at sentence #5270000, processed 143379232 words, keeping 4502199 word types\n",
      "2018-11-18 19:37:40,338 : INFO : PROGRESS: at sentence #5280000, processed 143658609 words, keeping 4510778 word types\n",
      "2018-11-18 19:37:40,394 : INFO : PROGRESS: at sentence #5290000, processed 143937747 words, keeping 4517237 word types\n",
      "2018-11-18 19:37:40,449 : INFO : PROGRESS: at sentence #5300000, processed 144209194 words, keeping 4523310 word types\n",
      "2018-11-18 19:37:40,506 : INFO : PROGRESS: at sentence #5310000, processed 144483778 words, keeping 4528917 word types\n",
      "2018-11-18 19:37:40,563 : INFO : PROGRESS: at sentence #5320000, processed 144774342 words, keeping 4536664 word types\n",
      "2018-11-18 19:37:40,619 : INFO : PROGRESS: at sentence #5330000, processed 145054221 words, keeping 4546971 word types\n",
      "2018-11-18 19:37:40,677 : INFO : PROGRESS: at sentence #5340000, processed 145348985 words, keeping 4554554 word types\n",
      "2018-11-18 19:37:40,732 : INFO : PROGRESS: at sentence #5350000, processed 145626599 words, keeping 4560700 word types\n",
      "2018-11-18 19:37:40,792 : INFO : PROGRESS: at sentence #5360000, processed 145918279 words, keeping 4568332 word types\n",
      "2018-11-18 19:37:40,847 : INFO : PROGRESS: at sentence #5370000, processed 146198654 words, keeping 4574584 word types\n",
      "2018-11-18 19:37:40,904 : INFO : PROGRESS: at sentence #5380000, processed 146483821 words, keeping 4581335 word types\n",
      "2018-11-18 19:37:40,957 : INFO : PROGRESS: at sentence #5390000, processed 146746542 words, keeping 4587562 word types\n",
      "2018-11-18 19:37:41,011 : INFO : PROGRESS: at sentence #5400000, processed 147015682 words, keeping 4594930 word types\n",
      "2018-11-18 19:37:41,067 : INFO : PROGRESS: at sentence #5410000, processed 147292092 words, keeping 4600163 word types\n",
      "2018-11-18 19:37:41,125 : INFO : PROGRESS: at sentence #5420000, processed 147580072 words, keeping 4607837 word types\n",
      "2018-11-18 19:37:41,184 : INFO : PROGRESS: at sentence #5430000, processed 147874794 words, keeping 4613789 word types\n",
      "2018-11-18 19:37:41,241 : INFO : PROGRESS: at sentence #5440000, processed 148142883 words, keeping 4623019 word types\n",
      "2018-11-18 19:37:41,293 : INFO : PROGRESS: at sentence #5450000, processed 148390745 words, keeping 4630210 word types\n",
      "2018-11-18 19:37:41,353 : INFO : PROGRESS: at sentence #5460000, processed 148674066 words, keeping 4639483 word types\n",
      "2018-11-18 19:37:41,406 : INFO : PROGRESS: at sentence #5470000, processed 148930369 words, keeping 4648224 word types\n",
      "2018-11-18 19:37:41,457 : INFO : PROGRESS: at sentence #5480000, processed 149190875 words, keeping 4654082 word types\n",
      "2018-11-18 19:37:41,514 : INFO : PROGRESS: at sentence #5490000, processed 149468338 words, keeping 4661860 word types\n",
      "2018-11-18 19:37:41,571 : INFO : PROGRESS: at sentence #5500000, processed 149754941 words, keeping 4667979 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-18 19:37:41,626 : INFO : PROGRESS: at sentence #5510000, processed 150027264 words, keeping 4675177 word types\n",
      "2018-11-18 19:37:41,684 : INFO : PROGRESS: at sentence #5520000, processed 150324707 words, keeping 4681514 word types\n",
      "2018-11-18 19:37:41,740 : INFO : PROGRESS: at sentence #5530000, processed 150610475 words, keeping 4689942 word types\n",
      "2018-11-18 19:37:41,796 : INFO : PROGRESS: at sentence #5540000, processed 150902149 words, keeping 4696860 word types\n",
      "2018-11-18 19:37:41,853 : INFO : PROGRESS: at sentence #5550000, processed 151183918 words, keeping 4705025 word types\n",
      "2018-11-18 19:37:41,906 : INFO : PROGRESS: at sentence #5560000, processed 151461165 words, keeping 4711414 word types\n",
      "2018-11-18 19:37:41,960 : INFO : PROGRESS: at sentence #5570000, processed 151728741 words, keeping 4718223 word types\n",
      "2018-11-18 19:37:42,015 : INFO : PROGRESS: at sentence #5580000, processed 151992893 words, keeping 4728625 word types\n",
      "2018-11-18 19:37:42,051 : INFO : collected 4732047 word types from a corpus of 152151471 raw words and 5585527 sentences\n",
      "2018-11-18 19:37:42,052 : INFO : Loading a fresh vocabulary\n",
      "2018-11-18 19:37:43,398 : INFO : effective_min_count=50 retains 81603 unique words (1% of original 4732047, drops 4650444)\n",
      "2018-11-18 19:37:43,399 : INFO : effective_min_count=50 leaves 141370502 word corpus (92% of original 152151471, drops 10780969)\n",
      "2018-11-18 19:37:43,585 : INFO : deleting the raw counts dictionary of 4732047 items\n",
      "2018-11-18 19:37:43,658 : INFO : sample=0.001 downsamples 44 most-common words\n",
      "2018-11-18 19:37:43,659 : INFO : downsampling leaves estimated 114877720 word corpus (81.3% of prior 141370502)\n",
      "2018-11-18 19:37:43,895 : INFO : estimated required memory for 81603 words and 300 dimensions: 236648700 bytes\n",
      "2018-11-18 19:37:43,896 : INFO : resetting layer weights\n",
      "2018-11-18 19:37:44,799 : INFO : training model with 4 workers on 81603 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=6\n",
      "2018-11-18 19:37:45,825 : INFO : EPOCH 1 - PROGRESS: at 1.08% examples, 1242536 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:37:46,830 : INFO : EPOCH 1 - PROGRESS: at 2.21% examples, 1239989 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:37:47,832 : INFO : EPOCH 1 - PROGRESS: at 3.34% examples, 1254156 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:37:48,837 : INFO : EPOCH 1 - PROGRESS: at 4.45% examples, 1261506 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:37:49,838 : INFO : EPOCH 1 - PROGRESS: at 5.55% examples, 1256965 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:37:50,841 : INFO : EPOCH 1 - PROGRESS: at 6.64% examples, 1242281 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:37:51,844 : INFO : EPOCH 1 - PROGRESS: at 7.71% examples, 1234944 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:37:52,849 : INFO : EPOCH 1 - PROGRESS: at 8.77% examples, 1234217 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:37:53,855 : INFO : EPOCH 1 - PROGRESS: at 9.84% examples, 1235163 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:37:54,856 : INFO : EPOCH 1 - PROGRESS: at 10.84% examples, 1230765 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:37:55,862 : INFO : EPOCH 1 - PROGRESS: at 11.91% examples, 1230388 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:37:56,863 : INFO : EPOCH 1 - PROGRESS: at 12.99% examples, 1232434 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:37:57,868 : INFO : EPOCH 1 - PROGRESS: at 14.10% examples, 1234810 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:37:58,875 : INFO : EPOCH 1 - PROGRESS: at 15.20% examples, 1237842 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:37:59,881 : INFO : EPOCH 1 - PROGRESS: at 16.32% examples, 1239302 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:38:00,882 : INFO : EPOCH 1 - PROGRESS: at 17.37% examples, 1239194 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:38:01,884 : INFO : EPOCH 1 - PROGRESS: at 18.44% examples, 1239789 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-18 19:38:02,893 : INFO : EPOCH 1 - PROGRESS: at 19.59% examples, 1242771 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:38:03,896 : INFO : EPOCH 1 - PROGRESS: at 20.69% examples, 1245201 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:38:04,900 : INFO : EPOCH 1 - PROGRESS: at 21.78% examples, 1246413 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:38:05,902 : INFO : EPOCH 1 - PROGRESS: at 22.92% examples, 1248951 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:38:06,904 : INFO : EPOCH 1 - PROGRESS: at 24.11% examples, 1251392 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:38:07,908 : INFO : EPOCH 1 - PROGRESS: at 25.31% examples, 1252918 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:38:08,908 : INFO : EPOCH 1 - PROGRESS: at 26.45% examples, 1254549 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:38:09,911 : INFO : EPOCH 1 - PROGRESS: at 27.57% examples, 1255631 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:38:10,914 : INFO : EPOCH 1 - PROGRESS: at 28.72% examples, 1257499 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:38:11,918 : INFO : EPOCH 1 - PROGRESS: at 29.85% examples, 1258361 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:38:12,919 : INFO : EPOCH 1 - PROGRESS: at 30.97% examples, 1258876 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:38:13,929 : INFO : EPOCH 1 - PROGRESS: at 32.08% examples, 1256702 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:38:14,930 : INFO : EPOCH 1 - PROGRESS: at 33.29% examples, 1256146 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:38:15,931 : INFO : EPOCH 1 - PROGRESS: at 34.32% examples, 1254727 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:38:16,939 : INFO : EPOCH 1 - PROGRESS: at 35.49% examples, 1255453 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:38:17,946 : INFO : EPOCH 1 - PROGRESS: at 36.63% examples, 1256443 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:38:18,947 : INFO : EPOCH 1 - PROGRESS: at 37.72% examples, 1256298 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:38:19,950 : INFO : EPOCH 1 - PROGRESS: at 38.86% examples, 1256541 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:38:20,955 : INFO : EPOCH 1 - PROGRESS: at 39.93% examples, 1255491 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:38:21,959 : INFO : EPOCH 1 - PROGRESS: at 40.96% examples, 1254048 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:38:22,966 : INFO : EPOCH 1 - PROGRESS: at 42.00% examples, 1254082 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:38:23,973 : INFO : EPOCH 1 - PROGRESS: at 43.01% examples, 1251689 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:38:24,977 : INFO : EPOCH 1 - PROGRESS: at 44.07% examples, 1249783 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:38:25,979 : INFO : EPOCH 1 - PROGRESS: at 45.14% examples, 1249265 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:38:26,989 : INFO : EPOCH 1 - PROGRESS: at 46.27% examples, 1248452 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:38:27,998 : INFO : EPOCH 1 - PROGRESS: at 47.30% examples, 1246820 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:38:29,000 : INFO : EPOCH 1 - PROGRESS: at 48.37% examples, 1245417 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:38:30,002 : INFO : EPOCH 1 - PROGRESS: at 49.43% examples, 1245027 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:38:31,006 : INFO : EPOCH 1 - PROGRESS: at 50.49% examples, 1244605 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:38:32,008 : INFO : EPOCH 1 - PROGRESS: at 51.64% examples, 1245204 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:38:33,011 : INFO : EPOCH 1 - PROGRESS: at 52.79% examples, 1246078 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:38:34,011 : INFO : EPOCH 1 - PROGRESS: at 53.92% examples, 1246787 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:38:35,011 : INFO : EPOCH 1 - PROGRESS: at 55.01% examples, 1247303 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:38:36,018 : INFO : EPOCH 1 - PROGRESS: at 56.08% examples, 1246206 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:38:37,018 : INFO : EPOCH 1 - PROGRESS: at 57.21% examples, 1246798 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:38:38,025 : INFO : EPOCH 1 - PROGRESS: at 58.30% examples, 1246970 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-18 19:38:39,026 : INFO : EPOCH 1 - PROGRESS: at 59.41% examples, 1247184 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:38:40,036 : INFO : EPOCH 1 - PROGRESS: at 60.57% examples, 1247930 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:38:41,037 : INFO : EPOCH 1 - PROGRESS: at 61.71% examples, 1248292 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:38:42,037 : INFO : EPOCH 1 - PROGRESS: at 62.80% examples, 1247360 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:38:43,039 : INFO : EPOCH 1 - PROGRESS: at 63.95% examples, 1247558 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:38:44,046 : INFO : EPOCH 1 - PROGRESS: at 65.03% examples, 1245635 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:38:45,048 : INFO : EPOCH 1 - PROGRESS: at 66.06% examples, 1243821 words/s, in_qsize 6, out_qsize 1\n",
      "2018-11-18 19:38:46,049 : INFO : EPOCH 1 - PROGRESS: at 67.06% examples, 1243136 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:38:47,051 : INFO : EPOCH 1 - PROGRESS: at 68.14% examples, 1243319 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:38:48,058 : INFO : EPOCH 1 - PROGRESS: at 69.24% examples, 1243875 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:38:49,062 : INFO : EPOCH 1 - PROGRESS: at 70.30% examples, 1244199 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:38:50,073 : INFO : EPOCH 1 - PROGRESS: at 71.40% examples, 1244937 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:38:51,076 : INFO : EPOCH 1 - PROGRESS: at 72.37% examples, 1243676 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:38:52,076 : INFO : EPOCH 1 - PROGRESS: at 73.41% examples, 1243411 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:38:53,080 : INFO : EPOCH 1 - PROGRESS: at 74.49% examples, 1243799 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:38:54,091 : INFO : EPOCH 1 - PROGRESS: at 75.59% examples, 1245002 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:38:55,097 : INFO : EPOCH 1 - PROGRESS: at 76.74% examples, 1245965 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:38:56,098 : INFO : EPOCH 1 - PROGRESS: at 77.80% examples, 1245964 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:38:57,106 : INFO : EPOCH 1 - PROGRESS: at 78.89% examples, 1245957 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:38:58,111 : INFO : EPOCH 1 - PROGRESS: at 79.93% examples, 1245751 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:38:59,119 : INFO : EPOCH 1 - PROGRESS: at 80.94% examples, 1244449 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:39:00,122 : INFO : EPOCH 1 - PROGRESS: at 81.95% examples, 1243513 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:39:01,123 : INFO : EPOCH 1 - PROGRESS: at 82.97% examples, 1242871 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:39:02,129 : INFO : EPOCH 1 - PROGRESS: at 84.03% examples, 1242743 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:39:03,131 : INFO : EPOCH 1 - PROGRESS: at 85.11% examples, 1243112 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:39:04,133 : INFO : EPOCH 1 - PROGRESS: at 86.19% examples, 1243637 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:39:05,140 : INFO : EPOCH 1 - PROGRESS: at 87.23% examples, 1243926 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:39:06,144 : INFO : EPOCH 1 - PROGRESS: at 88.31% examples, 1243860 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:39:07,149 : INFO : EPOCH 1 - PROGRESS: at 89.39% examples, 1244086 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:39:08,153 : INFO : EPOCH 1 - PROGRESS: at 90.46% examples, 1244543 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:39:09,156 : INFO : EPOCH 1 - PROGRESS: at 91.51% examples, 1244667 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:39:10,159 : INFO : EPOCH 1 - PROGRESS: at 92.60% examples, 1244559 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:39:11,160 : INFO : EPOCH 1 - PROGRESS: at 93.70% examples, 1244747 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:39:12,163 : INFO : EPOCH 1 - PROGRESS: at 94.79% examples, 1245265 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:39:13,168 : INFO : EPOCH 1 - PROGRESS: at 95.86% examples, 1245572 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:39:14,175 : INFO : EPOCH 1 - PROGRESS: at 96.95% examples, 1245785 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:39:15,176 : INFO : EPOCH 1 - PROGRESS: at 98.10% examples, 1246270 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-18 19:39:16,179 : INFO : EPOCH 1 - PROGRESS: at 99.17% examples, 1246658 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:39:16,937 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-18 19:39:16,941 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-18 19:39:16,950 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-18 19:39:16,951 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-18 19:39:16,952 : INFO : EPOCH - 1 : training on 152151471 raw words (114882307 effective words) took 92.2s, 1246649 effective words/s\n",
      "2018-11-18 19:39:17,959 : INFO : EPOCH 2 - PROGRESS: at 1.07% examples, 1241786 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-18 19:39:18,962 : INFO : EPOCH 2 - PROGRESS: at 2.24% examples, 1263068 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:39:19,963 : INFO : EPOCH 2 - PROGRESS: at 3.37% examples, 1267819 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:39:20,964 : INFO : EPOCH 2 - PROGRESS: at 4.47% examples, 1271259 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:39:21,964 : INFO : EPOCH 2 - PROGRESS: at 5.60% examples, 1273693 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:39:22,968 : INFO : EPOCH 2 - PROGRESS: at 6.79% examples, 1272037 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:39:23,970 : INFO : EPOCH 2 - PROGRESS: at 7.91% examples, 1273243 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:39:24,976 : INFO : EPOCH 2 - PROGRESS: at 9.03% examples, 1274136 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:39:25,976 : INFO : EPOCH 2 - PROGRESS: at 10.12% examples, 1273909 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:39:26,980 : INFO : EPOCH 2 - PROGRESS: at 11.17% examples, 1272039 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:39:27,981 : INFO : EPOCH 2 - PROGRESS: at 12.25% examples, 1271462 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:39:28,982 : INFO : EPOCH 2 - PROGRESS: at 13.36% examples, 1270303 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:39:29,989 : INFO : EPOCH 2 - PROGRESS: at 14.44% examples, 1267212 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:39:30,994 : INFO : EPOCH 2 - PROGRESS: at 15.54% examples, 1266975 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:39:31,994 : INFO : EPOCH 2 - PROGRESS: at 16.64% examples, 1267143 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:39:32,997 : INFO : EPOCH 2 - PROGRESS: at 17.75% examples, 1267794 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:39:33,997 : INFO : EPOCH 2 - PROGRESS: at 18.86% examples, 1268482 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:39:35,003 : INFO : EPOCH 2 - PROGRESS: at 19.94% examples, 1267662 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:39:36,014 : INFO : EPOCH 2 - PROGRESS: at 21.04% examples, 1267852 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:39:37,020 : INFO : EPOCH 2 - PROGRESS: at 22.13% examples, 1267793 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:39:38,021 : INFO : EPOCH 2 - PROGRESS: at 23.25% examples, 1267712 words/s, in_qsize 6, out_qsize 1\n",
      "2018-11-18 19:39:39,023 : INFO : EPOCH 2 - PROGRESS: at 24.43% examples, 1268380 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:39:40,027 : INFO : EPOCH 2 - PROGRESS: at 25.62% examples, 1268602 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:39:41,035 : INFO : EPOCH 2 - PROGRESS: at 26.74% examples, 1268986 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:39:42,038 : INFO : EPOCH 2 - PROGRESS: at 27.83% examples, 1267402 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-18 19:39:43,038 : INFO : EPOCH 2 - PROGRESS: at 28.89% examples, 1265815 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:39:44,048 : INFO : EPOCH 2 - PROGRESS: at 29.92% examples, 1261326 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:39:45,054 : INFO : EPOCH 2 - PROGRESS: at 31.02% examples, 1261267 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:39:46,057 : INFO : EPOCH 2 - PROGRESS: at 32.08% examples, 1257152 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:39:47,063 : INFO : EPOCH 2 - PROGRESS: at 33.22% examples, 1253866 words/s, in_qsize 7, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-18 19:39:48,068 : INFO : EPOCH 2 - PROGRESS: at 34.32% examples, 1254818 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:39:49,068 : INFO : EPOCH 2 - PROGRESS: at 35.51% examples, 1256744 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:39:50,072 : INFO : EPOCH 2 - PROGRESS: at 36.64% examples, 1257362 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:39:51,076 : INFO : EPOCH 2 - PROGRESS: at 37.79% examples, 1258916 words/s, in_qsize 7, out_qsize 1\n",
      "2018-11-18 19:39:52,076 : INFO : EPOCH 2 - PROGRESS: at 38.93% examples, 1259772 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:39:53,084 : INFO : EPOCH 2 - PROGRESS: at 40.09% examples, 1260927 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:39:54,085 : INFO : EPOCH 2 - PROGRESS: at 41.20% examples, 1262209 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:39:55,087 : INFO : EPOCH 2 - PROGRESS: at 42.32% examples, 1263730 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:39:56,090 : INFO : EPOCH 2 - PROGRESS: at 43.45% examples, 1264598 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:39:57,094 : INFO : EPOCH 2 - PROGRESS: at 44.61% examples, 1265812 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:39:58,098 : INFO : EPOCH 2 - PROGRESS: at 45.79% examples, 1266943 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:39:59,103 : INFO : EPOCH 2 - PROGRESS: at 46.94% examples, 1267557 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:40:00,106 : INFO : EPOCH 2 - PROGRESS: at 48.09% examples, 1268311 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:40:01,106 : INFO : EPOCH 2 - PROGRESS: at 49.16% examples, 1267354 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:40:02,113 : INFO : EPOCH 2 - PROGRESS: at 50.30% examples, 1268124 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:40:03,115 : INFO : EPOCH 2 - PROGRESS: at 51.44% examples, 1268136 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:40:04,118 : INFO : EPOCH 2 - PROGRESS: at 52.59% examples, 1268471 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:40:05,126 : INFO : EPOCH 2 - PROGRESS: at 53.75% examples, 1269061 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:40:06,129 : INFO : EPOCH 2 - PROGRESS: at 54.89% examples, 1269881 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:40:07,132 : INFO : EPOCH 2 - PROGRESS: at 56.02% examples, 1270391 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:40:08,136 : INFO : EPOCH 2 - PROGRESS: at 57.19% examples, 1271215 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:40:09,136 : INFO : EPOCH 2 - PROGRESS: at 58.33% examples, 1272056 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:40:10,137 : INFO : EPOCH 2 - PROGRESS: at 59.50% examples, 1273017 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:40:11,141 : INFO : EPOCH 2 - PROGRESS: at 60.65% examples, 1273377 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-18 19:40:12,144 : INFO : EPOCH 2 - PROGRESS: at 61.80% examples, 1273595 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:40:13,147 : INFO : EPOCH 2 - PROGRESS: at 63.00% examples, 1274081 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:40:14,154 : INFO : EPOCH 2 - PROGRESS: at 64.23% examples, 1273941 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:40:15,156 : INFO : EPOCH 2 - PROGRESS: at 65.28% examples, 1272340 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:40:16,158 : INFO : EPOCH 2 - PROGRESS: at 66.38% examples, 1271705 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:40:17,160 : INFO : EPOCH 2 - PROGRESS: at 67.47% examples, 1272456 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:40:18,166 : INFO : EPOCH 2 - PROGRESS: at 68.55% examples, 1271770 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:40:19,166 : INFO : EPOCH 2 - PROGRESS: at 69.65% examples, 1272636 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:40:20,168 : INFO : EPOCH 2 - PROGRESS: at 70.72% examples, 1272389 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:40:21,182 : INFO : EPOCH 2 - PROGRESS: at 71.82% examples, 1272416 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:40:22,194 : INFO : EPOCH 2 - PROGRESS: at 72.87% examples, 1272224 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:40:23,206 : INFO : EPOCH 2 - PROGRESS: at 73.94% examples, 1272067 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:40:24,213 : INFO : EPOCH 2 - PROGRESS: at 75.06% examples, 1272519 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:40:25,219 : INFO : EPOCH 2 - PROGRESS: at 76.15% examples, 1273032 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:40:26,233 : INFO : EPOCH 2 - PROGRESS: at 77.25% examples, 1272553 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:40:27,238 : INFO : EPOCH 2 - PROGRESS: at 78.31% examples, 1272182 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:40:28,242 : INFO : EPOCH 2 - PROGRESS: at 79.37% examples, 1271487 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:40:29,245 : INFO : EPOCH 2 - PROGRESS: at 80.44% examples, 1271466 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:40:30,246 : INFO : EPOCH 2 - PROGRESS: at 81.56% examples, 1271258 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:40:31,248 : INFO : EPOCH 2 - PROGRESS: at 82.66% examples, 1271554 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:40:32,252 : INFO : EPOCH 2 - PROGRESS: at 83.71% examples, 1271165 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:40:33,259 : INFO : EPOCH 2 - PROGRESS: at 84.81% examples, 1271477 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:40:34,259 : INFO : EPOCH 2 - PROGRESS: at 85.86% examples, 1271088 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:40:35,260 : INFO : EPOCH 2 - PROGRESS: at 86.89% examples, 1270641 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:40:36,271 : INFO : EPOCH 2 - PROGRESS: at 87.93% examples, 1270027 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:40:37,275 : INFO : EPOCH 2 - PROGRESS: at 89.01% examples, 1269595 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:40:38,280 : INFO : EPOCH 2 - PROGRESS: at 90.06% examples, 1269480 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:40:39,288 : INFO : EPOCH 2 - PROGRESS: at 91.11% examples, 1268990 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:40:40,289 : INFO : EPOCH 2 - PROGRESS: at 92.10% examples, 1267982 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:40:41,290 : INFO : EPOCH 2 - PROGRESS: at 93.19% examples, 1267532 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:40:42,292 : INFO : EPOCH 2 - PROGRESS: at 94.31% examples, 1268052 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:40:43,292 : INFO : EPOCH 2 - PROGRESS: at 95.29% examples, 1266690 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:40:44,298 : INFO : EPOCH 2 - PROGRESS: at 96.26% examples, 1265378 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:40:45,308 : INFO : EPOCH 2 - PROGRESS: at 97.24% examples, 1263946 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:40:46,309 : INFO : EPOCH 2 - PROGRESS: at 98.30% examples, 1262862 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:40:47,319 : INFO : EPOCH 2 - PROGRESS: at 99.33% examples, 1262583 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:40:47,896 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-18 19:40:47,899 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-18 19:40:47,911 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-18 19:40:47,912 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-18 19:40:47,913 : INFO : EPOCH - 2 : training on 152151471 raw words (114879364 effective words) took 91.0s, 1262779 effective words/s\n",
      "2018-11-18 19:40:48,925 : INFO : EPOCH 3 - PROGRESS: at 1.07% examples, 1236468 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:40:49,927 : INFO : EPOCH 3 - PROGRESS: at 2.22% examples, 1249486 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:40:50,934 : INFO : EPOCH 3 - PROGRESS: at 3.33% examples, 1251296 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:40:51,942 : INFO : EPOCH 3 - PROGRESS: at 4.42% examples, 1252790 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:40:52,947 : INFO : EPOCH 3 - PROGRESS: at 5.49% examples, 1241385 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:40:53,960 : INFO : EPOCH 3 - PROGRESS: at 6.57% examples, 1225791 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:40:54,959 : INFO : EPOCH 3 - PROGRESS: at 7.66% examples, 1223617 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:40:55,961 : INFO : EPOCH 3 - PROGRESS: at 8.76% examples, 1231504 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:40:56,969 : INFO : EPOCH 3 - PROGRESS: at 9.86% examples, 1235810 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:40:57,969 : INFO : EPOCH 3 - PROGRESS: at 10.93% examples, 1239805 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:40:58,980 : INFO : EPOCH 3 - PROGRESS: at 12.05% examples, 1242937 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:40:59,980 : INFO : EPOCH 3 - PROGRESS: at 13.15% examples, 1245019 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:41:00,986 : INFO : EPOCH 3 - PROGRESS: at 14.26% examples, 1247637 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:41:01,993 : INFO : EPOCH 3 - PROGRESS: at 15.35% examples, 1248260 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:41:02,997 : INFO : EPOCH 3 - PROGRESS: at 16.41% examples, 1245140 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:41:04,004 : INFO : EPOCH 3 - PROGRESS: at 17.43% examples, 1241195 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:41:05,008 : INFO : EPOCH 3 - PROGRESS: at 18.53% examples, 1244126 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:41:06,011 : INFO : EPOCH 3 - PROGRESS: at 19.65% examples, 1244896 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:41:07,014 : INFO : EPOCH 3 - PROGRESS: at 20.75% examples, 1247233 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:41:08,023 : INFO : EPOCH 3 - PROGRESS: at 21.83% examples, 1248444 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:41:09,027 : INFO : EPOCH 3 - PROGRESS: at 22.97% examples, 1249856 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:41:10,032 : INFO : EPOCH 3 - PROGRESS: at 24.12% examples, 1250383 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:41:11,033 : INFO : EPOCH 3 - PROGRESS: at 25.28% examples, 1250149 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:41:12,036 : INFO : EPOCH 3 - PROGRESS: at 26.40% examples, 1250722 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:41:13,037 : INFO : EPOCH 3 - PROGRESS: at 27.49% examples, 1250682 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:41:14,042 : INFO : EPOCH 3 - PROGRESS: at 28.60% examples, 1251097 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:41:15,042 : INFO : EPOCH 3 - PROGRESS: at 29.70% examples, 1251290 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:41:16,045 : INFO : EPOCH 3 - PROGRESS: at 30.82% examples, 1251594 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:41:17,049 : INFO : EPOCH 3 - PROGRESS: at 32.02% examples, 1253214 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:41:18,055 : INFO : EPOCH 3 - PROGRESS: at 33.20% examples, 1251783 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:41:19,058 : INFO : EPOCH 3 - PROGRESS: at 34.28% examples, 1252157 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:41:20,063 : INFO : EPOCH 3 - PROGRESS: at 35.45% examples, 1253115 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:41:21,067 : INFO : EPOCH 3 - PROGRESS: at 36.55% examples, 1252911 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:41:22,072 : INFO : EPOCH 3 - PROGRESS: at 37.61% examples, 1251649 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:41:23,072 : INFO : EPOCH 3 - PROGRESS: at 38.75% examples, 1252750 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:41:24,074 : INFO : EPOCH 3 - PROGRESS: at 39.84% examples, 1251935 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:41:25,075 : INFO : EPOCH 3 - PROGRESS: at 40.89% examples, 1251490 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:41:26,075 : INFO : EPOCH 3 - PROGRESS: at 41.89% examples, 1250149 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:41:27,077 : INFO : EPOCH 3 - PROGRESS: at 42.96% examples, 1249870 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:41:28,081 : INFO : EPOCH 3 - PROGRESS: at 44.09% examples, 1250197 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-18 19:41:29,081 : INFO : EPOCH 3 - PROGRESS: at 45.19% examples, 1250820 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:41:30,081 : INFO : EPOCH 3 - PROGRESS: at 46.37% examples, 1251577 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:41:31,087 : INFO : EPOCH 3 - PROGRESS: at 47.36% examples, 1249076 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-18 19:41:32,089 : INFO : EPOCH 3 - PROGRESS: at 48.45% examples, 1247985 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:41:33,096 : INFO : EPOCH 3 - PROGRESS: at 49.58% examples, 1249004 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:41:34,101 : INFO : EPOCH 3 - PROGRESS: at 50.69% examples, 1248824 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:41:35,105 : INFO : EPOCH 3 - PROGRESS: at 51.73% examples, 1247537 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:41:36,108 : INFO : EPOCH 3 - PROGRESS: at 52.84% examples, 1247256 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:41:37,108 : INFO : EPOCH 3 - PROGRESS: at 53.89% examples, 1246272 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:41:38,108 : INFO : EPOCH 3 - PROGRESS: at 54.97% examples, 1246343 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:41:39,114 : INFO : EPOCH 3 - PROGRESS: at 55.88% examples, 1241936 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:41:40,122 : INFO : EPOCH 3 - PROGRESS: at 56.81% examples, 1238170 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:41:41,122 : INFO : EPOCH 3 - PROGRESS: at 57.78% examples, 1235971 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:41:42,123 : INFO : EPOCH 3 - PROGRESS: at 58.87% examples, 1235677 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-18 19:41:43,132 : INFO : EPOCH 3 - PROGRESS: at 59.91% examples, 1234872 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:41:44,143 : INFO : EPOCH 3 - PROGRESS: at 61.00% examples, 1234101 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:41:45,147 : INFO : EPOCH 3 - PROGRESS: at 62.10% examples, 1234171 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:41:46,150 : INFO : EPOCH 3 - PROGRESS: at 63.26% examples, 1234100 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:41:47,156 : INFO : EPOCH 3 - PROGRESS: at 64.35% examples, 1232572 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:41:48,158 : INFO : EPOCH 3 - PROGRESS: at 65.49% examples, 1233054 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:41:49,160 : INFO : EPOCH 3 - PROGRESS: at 66.57% examples, 1232788 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:41:50,163 : INFO : EPOCH 3 - PROGRESS: at 67.54% examples, 1231847 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:41:51,171 : INFO : EPOCH 3 - PROGRESS: at 68.61% examples, 1231863 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:41:52,180 : INFO : EPOCH 3 - PROGRESS: at 69.57% examples, 1230623 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:41:53,192 : INFO : EPOCH 3 - PROGRESS: at 70.57% examples, 1229805 words/s, in_qsize 8, out_qsize 1\n",
      "2018-11-18 19:41:54,194 : INFO : EPOCH 3 - PROGRESS: at 71.62% examples, 1229592 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:41:55,195 : INFO : EPOCH 3 - PROGRESS: at 72.60% examples, 1228852 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:41:56,199 : INFO : EPOCH 3 - PROGRESS: at 73.66% examples, 1229342 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:41:57,203 : INFO : EPOCH 3 - PROGRESS: at 74.73% examples, 1229830 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:41:58,212 : INFO : EPOCH 3 - PROGRESS: at 75.79% examples, 1230313 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:41:59,216 : INFO : EPOCH 3 - PROGRESS: at 76.89% examples, 1230557 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:42:00,221 : INFO : EPOCH 3 - PROGRESS: at 77.95% examples, 1230704 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:42:01,226 : INFO : EPOCH 3 - PROGRESS: at 79.03% examples, 1230881 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:42:02,235 : INFO : EPOCH 3 - PROGRESS: at 80.07% examples, 1230743 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:42:03,239 : INFO : EPOCH 3 - PROGRESS: at 81.17% examples, 1231152 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:42:04,240 : INFO : EPOCH 3 - PROGRESS: at 82.26% examples, 1231714 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:42:05,244 : INFO : EPOCH 3 - PROGRESS: at 83.36% examples, 1232353 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:42:06,245 : INFO : EPOCH 3 - PROGRESS: at 84.42% examples, 1232852 words/s, in_qsize 7, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-18 19:42:07,248 : INFO : EPOCH 3 - PROGRESS: at 85.50% examples, 1233262 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:42:08,253 : INFO : EPOCH 3 - PROGRESS: at 86.56% examples, 1233540 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:42:09,256 : INFO : EPOCH 3 - PROGRESS: at 87.63% examples, 1234069 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:42:10,263 : INFO : EPOCH 3 - PROGRESS: at 88.70% examples, 1234072 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:42:11,273 : INFO : EPOCH 3 - PROGRESS: at 89.76% examples, 1234198 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:42:12,273 : INFO : EPOCH 3 - PROGRESS: at 90.76% examples, 1233735 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:42:13,275 : INFO : EPOCH 3 - PROGRESS: at 91.65% examples, 1231716 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:42:14,276 : INFO : EPOCH 3 - PROGRESS: at 92.67% examples, 1230938 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:42:15,284 : INFO : EPOCH 3 - PROGRESS: at 93.78% examples, 1231281 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:42:16,285 : INFO : EPOCH 3 - PROGRESS: at 94.84% examples, 1231568 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:42:17,292 : INFO : EPOCH 3 - PROGRESS: at 95.92% examples, 1232080 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:42:18,294 : INFO : EPOCH 3 - PROGRESS: at 96.99% examples, 1232393 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:42:19,300 : INFO : EPOCH 3 - PROGRESS: at 98.13% examples, 1232717 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:42:20,307 : INFO : EPOCH 3 - PROGRESS: at 99.20% examples, 1233284 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:42:21,007 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-18 19:42:21,016 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-18 19:42:21,018 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-18 19:42:21,020 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-18 19:42:21,022 : INFO : EPOCH - 3 : training on 152151471 raw words (114881471 effective words) took 93.1s, 1233664 effective words/s\n",
      "2018-11-18 19:42:22,032 : INFO : EPOCH 4 - PROGRESS: at 1.09% examples, 1260111 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:42:23,033 : INFO : EPOCH 4 - PROGRESS: at 2.25% examples, 1265975 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:42:24,043 : INFO : EPOCH 4 - PROGRESS: at 3.39% examples, 1270302 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-18 19:42:25,045 : INFO : EPOCH 4 - PROGRESS: at 4.48% examples, 1270924 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:42:26,046 : INFO : EPOCH 4 - PROGRESS: at 5.59% examples, 1265872 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:42:27,048 : INFO : EPOCH 4 - PROGRESS: at 6.77% examples, 1266049 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:42:28,048 : INFO : EPOCH 4 - PROGRESS: at 7.86% examples, 1263239 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:42:29,058 : INFO : EPOCH 4 - PROGRESS: at 8.94% examples, 1258859 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:42:30,061 : INFO : EPOCH 4 - PROGRESS: at 10.03% examples, 1260254 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:42:31,067 : INFO : EPOCH 4 - PROGRESS: at 11.09% examples, 1260819 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:42:32,068 : INFO : EPOCH 4 - PROGRESS: at 12.14% examples, 1258066 words/s, in_qsize 8, out_qsize 1\n",
      "2018-11-18 19:42:33,071 : INFO : EPOCH 4 - PROGRESS: at 13.28% examples, 1259506 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:42:34,080 : INFO : EPOCH 4 - PROGRESS: at 14.38% examples, 1259441 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:42:35,081 : INFO : EPOCH 4 - PROGRESS: at 15.47% examples, 1259345 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:42:36,084 : INFO : EPOCH 4 - PROGRESS: at 16.57% examples, 1259919 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:42:37,091 : INFO : EPOCH 4 - PROGRESS: at 17.65% examples, 1259834 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:42:38,093 : INFO : EPOCH 4 - PROGRESS: at 18.76% examples, 1259406 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:42:39,093 : INFO : EPOCH 4 - PROGRESS: at 19.80% examples, 1257139 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:42:40,102 : INFO : EPOCH 4 - PROGRESS: at 20.88% examples, 1256550 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:42:41,105 : INFO : EPOCH 4 - PROGRESS: at 21.97% examples, 1257859 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:42:42,112 : INFO : EPOCH 4 - PROGRESS: at 23.13% examples, 1259275 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:42:43,115 : INFO : EPOCH 4 - PROGRESS: at 24.25% examples, 1258313 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:42:44,121 : INFO : EPOCH 4 - PROGRESS: at 25.44% examples, 1258811 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:42:45,135 : INFO : EPOCH 4 - PROGRESS: at 26.56% examples, 1259266 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:42:46,137 : INFO : EPOCH 4 - PROGRESS: at 27.67% examples, 1259537 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:42:47,143 : INFO : EPOCH 4 - PROGRESS: at 28.79% examples, 1259755 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:42:48,148 : INFO : EPOCH 4 - PROGRESS: at 29.89% examples, 1258761 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:42:49,156 : INFO : EPOCH 4 - PROGRESS: at 31.00% examples, 1258616 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:42:50,160 : INFO : EPOCH 4 - PROGRESS: at 32.23% examples, 1258214 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:42:51,160 : INFO : EPOCH 4 - PROGRESS: at 33.34% examples, 1257296 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:42:52,165 : INFO : EPOCH 4 - PROGRESS: at 34.42% examples, 1257103 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:42:53,165 : INFO : EPOCH 4 - PROGRESS: at 35.56% examples, 1257260 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:42:54,165 : INFO : EPOCH 4 - PROGRESS: at 36.65% examples, 1256892 words/s, in_qsize 6, out_qsize 1\n",
      "2018-11-18 19:42:55,172 : INFO : EPOCH 4 - PROGRESS: at 37.74% examples, 1256120 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:42:56,172 : INFO : EPOCH 4 - PROGRESS: at 38.87% examples, 1256631 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:42:57,173 : INFO : EPOCH 4 - PROGRESS: at 39.97% examples, 1256348 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:42:58,182 : INFO : EPOCH 4 - PROGRESS: at 41.03% examples, 1255597 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:42:59,189 : INFO : EPOCH 4 - PROGRESS: at 42.11% examples, 1256583 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:43:00,194 : INFO : EPOCH 4 - PROGRESS: at 43.21% examples, 1256592 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:43:01,202 : INFO : EPOCH 4 - PROGRESS: at 44.30% examples, 1255569 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:43:02,205 : INFO : EPOCH 4 - PROGRESS: at 45.36% examples, 1254441 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:43:03,211 : INFO : EPOCH 4 - PROGRESS: at 46.48% examples, 1253822 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:43:04,217 : INFO : EPOCH 4 - PROGRESS: at 47.53% examples, 1252862 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:43:05,223 : INFO : EPOCH 4 - PROGRESS: at 48.67% examples, 1252732 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:43:06,230 : INFO : EPOCH 4 - PROGRESS: at 49.71% examples, 1251956 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:43:07,239 : INFO : EPOCH 4 - PROGRESS: at 50.83% examples, 1251661 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:43:08,241 : INFO : EPOCH 4 - PROGRESS: at 51.96% examples, 1251736 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:43:09,244 : INFO : EPOCH 4 - PROGRESS: at 53.10% examples, 1252221 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:43:10,247 : INFO : EPOCH 4 - PROGRESS: at 54.20% examples, 1252798 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:43:11,251 : INFO : EPOCH 4 - PROGRESS: at 55.30% examples, 1253190 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:43:12,251 : INFO : EPOCH 4 - PROGRESS: at 56.44% examples, 1253531 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:43:13,251 : INFO : EPOCH 4 - PROGRESS: at 57.55% examples, 1253826 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:43:14,252 : INFO : EPOCH 4 - PROGRESS: at 58.67% examples, 1254053 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:43:15,253 : INFO : EPOCH 4 - PROGRESS: at 59.72% examples, 1253194 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:43:16,253 : INFO : EPOCH 4 - PROGRESS: at 60.84% examples, 1253450 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:43:17,258 : INFO : EPOCH 4 - PROGRESS: at 61.94% examples, 1252945 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:43:18,258 : INFO : EPOCH 4 - PROGRESS: at 63.09% examples, 1252738 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:43:19,259 : INFO : EPOCH 4 - PROGRESS: at 64.31% examples, 1253023 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:43:20,262 : INFO : EPOCH 4 - PROGRESS: at 65.46% examples, 1253548 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:43:21,266 : INFO : EPOCH 4 - PROGRESS: at 66.60% examples, 1253863 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:43:22,275 : INFO : EPOCH 4 - PROGRESS: at 67.65% examples, 1254049 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:43:23,278 : INFO : EPOCH 4 - PROGRESS: at 68.73% examples, 1254325 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:43:24,278 : INFO : EPOCH 4 - PROGRESS: at 69.81% examples, 1254659 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:43:25,283 : INFO : EPOCH 4 - PROGRESS: at 70.79% examples, 1253140 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:43:26,284 : INFO : EPOCH 4 - PROGRESS: at 71.84% examples, 1252638 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-18 19:43:27,283 : INFO : EPOCH 4 - PROGRESS: at 72.85% examples, 1252084 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-18 19:43:28,288 : INFO : EPOCH 4 - PROGRESS: at 73.80% examples, 1250583 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:43:29,289 : INFO : EPOCH 4 - PROGRESS: at 74.82% examples, 1249775 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:43:30,289 : INFO : EPOCH 4 - PROGRESS: at 75.78% examples, 1248490 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:43:31,290 : INFO : EPOCH 4 - PROGRESS: at 76.88% examples, 1248536 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:43:32,291 : INFO : EPOCH 4 - PROGRESS: at 77.91% examples, 1247865 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:43:33,293 : INFO : EPOCH 4 - PROGRESS: at 78.76% examples, 1244126 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:43:34,296 : INFO : EPOCH 4 - PROGRESS: at 79.62% examples, 1241071 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:43:35,298 : INFO : EPOCH 4 - PROGRESS: at 80.48% examples, 1238026 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:43:36,301 : INFO : EPOCH 4 - PROGRESS: at 81.48% examples, 1236736 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:43:37,304 : INFO : EPOCH 4 - PROGRESS: at 82.52% examples, 1236492 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:43:38,304 : INFO : EPOCH 4 - PROGRESS: at 83.54% examples, 1235936 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:43:39,304 : INFO : EPOCH 4 - PROGRESS: at 84.53% examples, 1235131 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:43:40,307 : INFO : EPOCH 4 - PROGRESS: at 85.49% examples, 1233825 words/s, in_qsize 6, out_qsize 1\n",
      "2018-11-18 19:43:41,313 : INFO : EPOCH 4 - PROGRESS: at 86.53% examples, 1233902 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:43:42,315 : INFO : EPOCH 4 - PROGRESS: at 87.52% examples, 1233220 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:43:43,323 : INFO : EPOCH 4 - PROGRESS: at 88.56% examples, 1232580 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:43:44,324 : INFO : EPOCH 4 - PROGRESS: at 89.53% examples, 1231578 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:43:45,325 : INFO : EPOCH 4 - PROGRESS: at 90.49% examples, 1230683 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:43:46,330 : INFO : EPOCH 4 - PROGRESS: at 91.46% examples, 1229840 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:43:47,337 : INFO : EPOCH 4 - PROGRESS: at 92.58% examples, 1230321 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:43:48,341 : INFO : EPOCH 4 - PROGRESS: at 93.67% examples, 1230621 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:43:49,348 : INFO : EPOCH 4 - PROGRESS: at 94.74% examples, 1230811 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:43:50,349 : INFO : EPOCH 4 - PROGRESS: at 95.72% examples, 1230155 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:43:51,352 : INFO : EPOCH 4 - PROGRESS: at 96.80% examples, 1230388 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:43:52,356 : INFO : EPOCH 4 - PROGRESS: at 97.93% examples, 1231027 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:43:53,357 : INFO : EPOCH 4 - PROGRESS: at 99.03% examples, 1231840 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:43:54,266 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-18 19:43:54,268 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-18 19:43:54,269 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-18 19:43:54,270 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-18 19:43:54,271 : INFO : EPOCH - 4 : training on 152151471 raw words (114879933 effective words) took 93.3s, 1231785 effective words/s\n",
      "2018-11-18 19:43:55,275 : INFO : EPOCH 5 - PROGRESS: at 1.09% examples, 1261163 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:43:56,282 : INFO : EPOCH 5 - PROGRESS: at 2.27% examples, 1278106 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:43:57,283 : INFO : EPOCH 5 - PROGRESS: at 3.39% examples, 1274457 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:43:58,289 : INFO : EPOCH 5 - PROGRESS: at 4.47% examples, 1271285 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:43:59,290 : INFO : EPOCH 5 - PROGRESS: at 5.60% examples, 1270671 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:44:00,291 : INFO : EPOCH 5 - PROGRESS: at 6.81% examples, 1275264 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:44:01,298 : INFO : EPOCH 5 - PROGRESS: at 7.89% examples, 1269815 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:44:02,300 : INFO : EPOCH 5 - PROGRESS: at 8.96% examples, 1263213 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:44:03,304 : INFO : EPOCH 5 - PROGRESS: at 10.01% examples, 1256608 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:44:04,308 : INFO : EPOCH 5 - PROGRESS: at 11.00% examples, 1251481 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:44:05,309 : INFO : EPOCH 5 - PROGRESS: at 12.09% examples, 1255214 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:44:06,314 : INFO : EPOCH 5 - PROGRESS: at 13.20% examples, 1253298 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:44:07,318 : INFO : EPOCH 5 - PROGRESS: at 14.30% examples, 1253710 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:44:08,322 : INFO : EPOCH 5 - PROGRESS: at 15.32% examples, 1248456 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:44:09,322 : INFO : EPOCH 5 - PROGRESS: at 16.41% examples, 1247528 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:44:10,337 : INFO : EPOCH 5 - PROGRESS: at 17.51% examples, 1249828 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:44:11,339 : INFO : EPOCH 5 - PROGRESS: at 18.58% examples, 1248789 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-18 19:44:12,339 : INFO : EPOCH 5 - PROGRESS: at 19.67% examples, 1248729 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:44:13,340 : INFO : EPOCH 5 - PROGRESS: at 20.78% examples, 1251835 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-18 19:44:14,346 : INFO : EPOCH 5 - PROGRESS: at 21.88% examples, 1253312 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:44:15,354 : INFO : EPOCH 5 - PROGRESS: at 23.01% examples, 1254080 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:44:16,365 : INFO : EPOCH 5 - PROGRESS: at 24.19% examples, 1255762 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:44:17,366 : INFO : EPOCH 5 - PROGRESS: at 25.39% examples, 1256616 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:44:18,368 : INFO : EPOCH 5 - PROGRESS: at 26.53% examples, 1258657 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:44:19,387 : INFO : EPOCH 5 - PROGRESS: at 27.60% examples, 1256625 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:44:20,391 : INFO : EPOCH 5 - PROGRESS: at 28.68% examples, 1254843 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:44:21,401 : INFO : EPOCH 5 - PROGRESS: at 29.74% examples, 1253037 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:44:22,404 : INFO : EPOCH 5 - PROGRESS: at 30.84% examples, 1252428 words/s, in_qsize 7, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-18 19:44:23,411 : INFO : EPOCH 5 - PROGRESS: at 32.00% examples, 1252417 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:44:24,411 : INFO : EPOCH 5 - PROGRESS: at 33.23% examples, 1253244 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:44:25,415 : INFO : EPOCH 5 - PROGRESS: at 34.34% examples, 1254269 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:44:26,419 : INFO : EPOCH 5 - PROGRESS: at 35.50% examples, 1255109 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:44:27,423 : INFO : EPOCH 5 - PROGRESS: at 36.63% examples, 1255789 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:44:28,423 : INFO : EPOCH 5 - PROGRESS: at 37.75% examples, 1256607 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:44:29,426 : INFO : EPOCH 5 - PROGRESS: at 38.90% examples, 1257686 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:44:30,426 : INFO : EPOCH 5 - PROGRESS: at 40.06% examples, 1259148 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:44:31,430 : INFO : EPOCH 5 - PROGRESS: at 41.16% examples, 1260201 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:44:32,437 : INFO : EPOCH 5 - PROGRESS: at 42.27% examples, 1261679 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:44:33,441 : INFO : EPOCH 5 - PROGRESS: at 43.38% examples, 1261925 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:44:34,448 : INFO : EPOCH 5 - PROGRESS: at 44.51% examples, 1262011 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:44:35,449 : INFO : EPOCH 5 - PROGRESS: at 45.54% examples, 1259610 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:44:36,459 : INFO : EPOCH 5 - PROGRESS: at 46.64% examples, 1258488 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:44:37,460 : INFO : EPOCH 5 - PROGRESS: at 47.73% examples, 1258180 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:44:38,462 : INFO : EPOCH 5 - PROGRESS: at 48.84% examples, 1257897 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:44:39,470 : INFO : EPOCH 5 - PROGRESS: at 49.96% examples, 1258485 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:44:40,480 : INFO : EPOCH 5 - PROGRESS: at 51.05% examples, 1257445 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:44:41,480 : INFO : EPOCH 5 - PROGRESS: at 52.09% examples, 1255287 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:44:42,487 : INFO : EPOCH 5 - PROGRESS: at 53.17% examples, 1254317 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:44:43,489 : INFO : EPOCH 5 - PROGRESS: at 54.24% examples, 1253937 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:44:44,493 : INFO : EPOCH 5 - PROGRESS: at 55.31% examples, 1253756 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:44:45,493 : INFO : EPOCH 5 - PROGRESS: at 56.45% examples, 1253919 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:44:46,496 : INFO : EPOCH 5 - PROGRESS: at 57.53% examples, 1253582 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:44:47,504 : INFO : EPOCH 5 - PROGRESS: at 58.66% examples, 1253748 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:44:48,504 : INFO : EPOCH 5 - PROGRESS: at 59.73% examples, 1253491 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:44:49,504 : INFO : EPOCH 5 - PROGRESS: at 60.87% examples, 1254009 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:44:50,505 : INFO : EPOCH 5 - PROGRESS: at 61.98% examples, 1253693 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:44:51,511 : INFO : EPOCH 5 - PROGRESS: at 63.18% examples, 1254142 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:44:52,527 : INFO : EPOCH 5 - PROGRESS: at 64.38% examples, 1254091 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:44:53,533 : INFO : EPOCH 5 - PROGRESS: at 65.54% examples, 1254522 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:44:54,535 : INFO : EPOCH 5 - PROGRESS: at 66.65% examples, 1254376 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:44:55,536 : INFO : EPOCH 5 - PROGRESS: at 67.66% examples, 1253979 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:44:56,540 : INFO : EPOCH 5 - PROGRESS: at 68.72% examples, 1253734 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:44:57,541 : INFO : EPOCH 5 - PROGRESS: at 69.78% examples, 1253828 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:44:58,544 : INFO : EPOCH 5 - PROGRESS: at 70.84% examples, 1254132 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:44:59,555 : INFO : EPOCH 5 - PROGRESS: at 71.95% examples, 1254418 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:45:00,558 : INFO : EPOCH 5 - PROGRESS: at 73.01% examples, 1254683 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:45:01,559 : INFO : EPOCH 5 - PROGRESS: at 74.08% examples, 1255006 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:45:02,571 : INFO : EPOCH 5 - PROGRESS: at 75.15% examples, 1254721 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:45:03,580 : INFO : EPOCH 5 - PROGRESS: at 76.16% examples, 1254140 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:45:04,580 : INFO : EPOCH 5 - PROGRESS: at 77.16% examples, 1252576 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:45:05,581 : INFO : EPOCH 5 - PROGRESS: at 78.25% examples, 1252976 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:45:06,581 : INFO : EPOCH 5 - PROGRESS: at 79.25% examples, 1251583 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:45:07,590 : INFO : EPOCH 5 - PROGRESS: at 80.24% examples, 1250408 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:45:08,593 : INFO : EPOCH 5 - PROGRESS: at 81.35% examples, 1250623 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:45:09,598 : INFO : EPOCH 5 - PROGRESS: at 82.42% examples, 1250457 words/s, in_qsize 8, out_qsize 1\n",
      "2018-11-18 19:45:10,602 : INFO : EPOCH 5 - PROGRESS: at 83.52% examples, 1251028 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:45:11,609 : INFO : EPOCH 5 - PROGRESS: at 84.62% examples, 1251769 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:45:12,617 : INFO : EPOCH 5 - PROGRESS: at 85.66% examples, 1251275 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:45:13,621 : INFO : EPOCH 5 - PROGRESS: at 86.68% examples, 1250607 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:45:14,628 : INFO : EPOCH 5 - PROGRESS: at 87.71% examples, 1250403 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:45:15,629 : INFO : EPOCH 5 - PROGRESS: at 88.77% examples, 1250030 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-18 19:45:16,629 : INFO : EPOCH 5 - PROGRESS: at 89.75% examples, 1249094 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:45:17,638 : INFO : EPOCH 5 - PROGRESS: at 90.76% examples, 1248404 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:45:18,643 : INFO : EPOCH 5 - PROGRESS: at 91.77% examples, 1247878 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:45:19,654 : INFO : EPOCH 5 - PROGRESS: at 92.84% examples, 1247321 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:45:20,658 : INFO : EPOCH 5 - PROGRESS: at 93.88% examples, 1246688 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:45:21,662 : INFO : EPOCH 5 - PROGRESS: at 94.97% examples, 1247103 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:45:22,664 : INFO : EPOCH 5 - PROGRESS: at 96.06% examples, 1247781 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:45:23,666 : INFO : EPOCH 5 - PROGRESS: at 97.12% examples, 1247727 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:45:24,668 : INFO : EPOCH 5 - PROGRESS: at 98.24% examples, 1247530 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:45:25,671 : INFO : EPOCH 5 - PROGRESS: at 99.26% examples, 1247403 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-18 19:45:26,338 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-18 19:45:26,341 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-18 19:45:26,347 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-18 19:45:26,352 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-18 19:45:26,353 : INFO : EPOCH - 5 : training on 152151471 raw words (114878923 effective words) took 92.1s, 1247392 effective words/s\n",
      "2018-11-18 19:45:26,354 : INFO : training on a 760757355 raw words (574401998 effective words) took 461.6s, 1244263 effective words/s\n"
     ]
    }
   ],
   "source": [
    "model = word2vec.Word2Vec(sentences, workers=num_workers, \\\n",
    "            size=num_features, min_count = min_word_count, \\\n",
    "            window = context, sample = downsampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-18 19:47:04,866 : INFO : saving Word2Vec object under medium_w2v_model, separately None\n",
      "2018-11-18 19:47:04,868 : INFO : storing np array 'vectors' to medium_w2v_model.wv.vectors.npy\n",
      "2018-11-18 19:47:05,110 : INFO : not storing attribute vectors_norm\n",
      "2018-11-18 19:47:05,112 : INFO : storing np array 'syn1neg' to medium_w2v_model.trainables.syn1neg.npy\n",
      "2018-11-18 19:47:05,347 : INFO : not storing attribute cum_table\n",
      "2018-11-18 19:47:05,518 : INFO : saved medium_w2v_model\n"
     ]
    }
   ],
   "source": [
    "model_name = \"medium_w2v_model\"\n",
    "model.save(model_name)\n",
    "#new_model = gensim.models.Word2Vec.load('medium_w2v_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexander.brukhanov\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "w2v = dict(zip(model.wv.index2word, model.wv.syn0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fingerprint(text, model, weights=False):\n",
    "    \"\"\"\n",
    "    :param text: list of words\n",
    "    :param model: word2vec model in Gensim format\n",
    "    :param weights: whether to use word weights based on frequencies (word2vec model should contain frequency data)\n",
    "    :return: average vector of words in text\n",
    "    \"\"\"\n",
    "    # Creating list of all words in the document, which are present in the model\n",
    "    words = [w for w in text if w in model]\n",
    "    lexicon = list(set(words))\n",
    "    lw = len(lexicon)\n",
    "    if lw < 1:\n",
    "        print('Empty lexicon in', text)\n",
    "        return np.zeros(model.vector_size)\n",
    "    vectors = np.zeros((lw, model.vector_size))  # Creating empty matrix of vectors for words\n",
    "    for i in list(range(lw)):  # Iterate over words in the text\n",
    "        word = lexicon[i]\n",
    "        if weights:\n",
    "            weight = wordweight(word, model)\n",
    "        else:\n",
    "            weight = 1.0\n",
    "        vectors[i, :] = model[word] * weight  # Adding word and its vector to matrix\n",
    "    semantic_fingerprint = np.sum(vectors, axis=0)  # Computing sum of all vectors in the document\n",
    "    semantic_fingerprint = np.divide(semantic_fingerprint, lw)  # Computing average vector\n",
    "    return semantic_fingerprint\n",
    "\n",
    "\n",
    "def wordweight(word, model, a=10 ** -3, wcount=250000000):\n",
    "    \"\"\"\n",
    "    :param word: word token\n",
    "    :param model: word2vec model in Gensim format\n",
    "    :param a: smoothing coefficient\n",
    "    :param wcount: number of words in the training corpus (the default value corresponds to the RNC)\n",
    "    :return: word weight (rare words get higher weights)\n",
    "    \"\"\"\n",
    "    prob = model.wv.vocab[word].count / wcount\n",
    "    weight = a / (a + prob)\n",
    "    return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.vector_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexander.brukhanov\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\alexander.brukhanov\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    }
   ],
   "source": [
    "matrix = np.empty((X_train_content_sparse.shape[0], model.vector_size))\n",
    "content_list = X_train_content_sparse['content'].tolist()\n",
    "\n",
    "for i in range(0,len(X_train_content_sparse)):\n",
    "    try:\n",
    "        # Need to first change \"./.\" to \".\" so that sentences parse correctly\n",
    "        oped = content_list[i].replace(\"/.\", '')\n",
    "        # Now apply functions\n",
    "        sentence = sentence_to_wordlist(oped, tokenizer)\n",
    "        #print(sentence)\n",
    "        #bow = [b for b in sentence]\n",
    "        #print(bow)\n",
    "        fp = fingerprint(sentence, model, 0)\n",
    "        #if \"error\" not in q:\n",
    "        #    bow = q.split()\n",
    "        #    bow = [b for b in bow]\n",
    "        #    fp = fingerprint(bow, model, 0)\n",
    "        #else:\n",
    "        #    print('Error at ', q)\n",
    "        matrix[i, :] = fp\n",
    "    except:\n",
    "        print('no!')\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62313, 300)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexander.brukhanov\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\alexander.brukhanov\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    }
   ],
   "source": [
    "matrix_test = np.empty((X_test_content_sparse.shape[0], model.vector_size))\n",
    "content_list = X_test_content_sparse['content'].tolist()\n",
    "\n",
    "for i in range(0,len(X_test_content_sparse)):\n",
    "    try:\n",
    "        # Need to first change \"./.\" to \".\" so that sentences parse correctly\n",
    "        oped = content_list[i].replace(\"/.\", '')\n",
    "        # Now apply functions\n",
    "        sentence = sentence_to_wordlist(oped, tokenizer)\n",
    "        #print(sentence)\n",
    "        #bow = [b for b in sentence]\n",
    "        #print(bow)\n",
    "        fp = fingerprint(sentence, model, 0)\n",
    "        #if \"error\" not in q:\n",
    "        #    bow = q.split()\n",
    "        #    bow = [b for b in bow]\n",
    "        #    fp = fingerprint(bow, model, 0)\n",
    "        #else:\n",
    "        #    print('Error at ', q)\n",
    "        matrix_test[i, :] = fp\n",
    "    except:\n",
    "        print('no!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_image_sparse = pd.read_csv(PATH_TO_DATA+'/train_image.txt', sep=\"\\n\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_image_sparse = pd.read_csv(PATH_TO_DATA+'/test_image.txt', sep=\"\\n\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_image_sparse=X_test_image_sparse.rename(columns={0: \"image\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 34645 entries, 0 to 34644\n",
      "Data columns (total 1 columns):\n",
      "image    34645 non-null object\n",
      "dtypes: object(1)\n",
      "memory usage: 270.7+ KB\n"
     ]
    }
   ],
   "source": [
    "X_test_image_sparse.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_image_sparse['image'] = X_train_image_sparse['image'].apply(lambda x: 0 if x == 'None' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 62313 entries, 0 to 62312\n",
      "Data columns (total 1 columns):\n",
      "image    62313 non-null int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 486.9 KB\n"
     ]
    }
   ],
   "source": [
    "X_train_image_sparse.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_image_sparse['image'] = X_test_image_sparse['image'].apply(lambda x: 0 if x == 'None' else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Join all sparse matrices.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_content_sparse = matrix\n",
    "X_train_sparse = hstack([X_train_content_sparse, X_train_image_sparse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_content_sparse = matrix_test\n",
    "X_test_sparse = hstack([X_test_content_sparse, X_test_image_sparse])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.coo.coo_matrix"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train_sparse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read train target and split data for validation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target = pd.read_csv(os.path.join(PATH_TO_DATA, 'train_log1p_recommends.csv'), \n",
    "                           index_col='id')\n",
    "y_train = train_target['log_recommends'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'coo_matrix' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-191-62beb3dd59d5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtrain_part_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.7\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX_train_part_sparse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train_sparse\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtrain_part_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0my_train_part\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtrain_part_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mX_valid_sparse\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mX_train_sparse\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_part_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0my_valid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_part_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'coo_matrix' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "train_part_size = int(0.7 * train_target.shape[0])\n",
    "X_train_part_sparse = X_train_sparse[:train_part_size, :]\n",
    "y_train_part = y_train[:train_part_size]\n",
    "X_valid_sparse =  X_train_sparse[train_part_size:, :]\n",
    "y_valid = y_train[train_part_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train a simple Ridge model and check MAE on the validation set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "ridge = Ridge(random_state=17)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.68 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=17, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "ridge.fit(X_train_part_sparse, y_train_part);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_pred = ridge.predict(X_valid_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_valid, bins=30, alpha=.5, color='red', label='true', range=(0,10));\n",
    "plt.hist(ridge_pred, bins=30, alpha=.5, color='green', label='pred', range=(0,10));\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.2816719069073894, 2.602658001966898)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_mae = mean_absolute_error(y_valid, ridge_pred)\n",
    "valid_mae, np.expm1(valid_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train the same Ridge with all available data, make predictions for the test set and form a submission file.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 285 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=17, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "ridge.fit(X_train_sparse, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 21.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ridge_test_pred = ridge.predict(X_test_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_submission_file(prediction, filename,\n",
    "                          path_to_sample=os.path.join(PATH_TO_DATA, \n",
    "                                                      'sample_submission.csv')):\n",
    "    submission = pd.read_csv(path_to_sample, index_col='id')\n",
    "    \n",
    "    submission['log_recommends'] = prediction\n",
    "    submission.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission_file(ridge_test_pred, os.path.join(PATH_TO_DATA,\n",
    "                                                    'assignment6_medium_submission.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now's the time for dirty Kaggle hacks. Form a submission file with all zeros. Make a submission. What do you get if you think about it? How is it going to help you with modifying your predictions?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission_file(np.zeros_like(ridge_test_pred), \n",
    "                      os.path.join(PATH_TO_DATA,\n",
    "                                   'medium_all_zeros_submission.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modify predictions in an appropriate way (based on your all-zero submission) and make a new submission.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_test_pred_modif = ridge_test_pred # You code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission_file(ridge_test_pred_modif, \n",
    "                      os.path.join(PATH_TO_DATA,\n",
    "                                   'assignment6_medium_submission_with_hack.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Input\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import regularizers\n",
    "from keras.wrappers.scikit_learn import KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Опишем нашу сеть.\n",
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_dim=X_train_part_sparse.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "estimator = KerasRegressor(build_fn=baseline_model,epochs=20, nb_epoch=20, batch_size=64,validation_data=(X_valid_sparse, y_valid), verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 43619 samples, validate on 18694 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "GPU sync failed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: GPU sync failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-128-2ff75d863494>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_part_sparse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_part\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    150\u001b[0m         \u001b[0mfit_args\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m         \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1037\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1038\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2657\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2658\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_make_callable_from_options'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2659\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2660\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[1;34m()\u001b[0m\n\u001b[0;32m    195\u001b[0m                 \u001b[1;31m# not already marked as initialized.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m                 is_initialized = session.run(\n\u001b[1;32m--> 197\u001b[1;33m                     [tf.is_variable_initialized(v) for v in candidate_vars])\n\u001b[0m\u001b[0;32m    198\u001b[0m                 \u001b[0muninitialized_vars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mflag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_initialized\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcandidate_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1333\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1334\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1335\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1337\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: GPU sync failed"
     ]
    }
   ],
   "source": [
    "estimator.fit(X_train_part_sparse, y_train_part)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it for the assignment. Much more credits will be given to the winners in this competition, check [course roadmap](https://mlcourse.ai/roadmap). Do not spoil the assignment and the competition - don't share high-performing kernels (with MAE < 1.5).\n",
    "\n",
    "Some ideas for improvement:\n",
    "\n",
    "- Engineer good features, this is the key to success. Some simple features will be based on publication time, authors, content length and so on\n",
    "- You may not ignore HTML and extract some features from there\n",
    "- You'd better experiment with your validation scheme. You should see a correlation between your local improvements and LB score\n",
    "- Try TF-IDF, ngrams, Word2Vec and GloVe embeddings\n",
    "- Try various NLP techniques like stemming and lemmatization\n",
    "- Tune hyperparameters. In our example, we've left only 50k features and used C=1 as a regularization parameter, this can be changed\n",
    "- SGD and Vowpal Wabbit will learn much faster\n",
    "- Play around with blending and/or stacking. An intro is given in [this Kernel](https://www.kaggle.com/kashnitsky/ridge-and-lightgbm-simple-blending) by @yorko \n",
    "- In our course, we don't cover neural nets. But it's not obliged to use GRUs/LSTMs/whatever in this competition.\n",
    "\n",
    "Good luck!\n",
    "\n",
    "<img src='../../img/kaggle_shakeup.png' width=50%>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
